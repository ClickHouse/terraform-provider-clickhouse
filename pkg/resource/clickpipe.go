//go:build alpha

package resource

import (
	"context"
	"fmt"
	"strings"

	"github.com/ClickHouse/terraform-provider-clickhouse/pkg/internal/api"
	"github.com/ClickHouse/terraform-provider-clickhouse/pkg/internal/utils"
	"github.com/ClickHouse/terraform-provider-clickhouse/pkg/resource/models"
	"github.com/hashicorp/terraform-plugin-framework-validators/float64validator"
	"github.com/hashicorp/terraform-plugin-framework-validators/int64validator"
	"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator"
	"github.com/hashicorp/terraform-plugin-framework/attr"
	"github.com/hashicorp/terraform-plugin-framework/diag"
	"github.com/hashicorp/terraform-plugin-framework/path"
	"github.com/hashicorp/terraform-plugin-framework/resource"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/booldefault"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/boolplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/int64default"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/listplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/objectplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringdefault"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/schema/validator"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-framework/types/basetypes"
)

var (
	_ resource.Resource                = &ClickPipeResource{}
	_ resource.ResourceWithModifyPlan  = &ClickPipeResource{}
	_ resource.ResourceWithConfigure   = &ClickPipeResource{}
	_ resource.ResourceWithImportState = &ClickPipeResource{}
)

const clickPipeResourceDescription = `
This experimental resource allows you to create and manage ClickPipes data ingestion in ClickHouse Cloud.

**Resource is early access and may change in future releases. Feature coverage might not fully cover all ClickPipe capabilities.**

Known limitations:
- ClickPipe does not support table updates for managed tables. If you need to update the table schema, you will have to do that externally.
`

const (
	clickPipeStateChangeMaxWaitSeconds = 60 * 2
)

type ClickPipeResource struct {
	client api.Client
}

func NewClickPipeResource() resource.Resource {
	return &ClickPipeResource{}
}

func (c *ClickPipeResource) Configure(_ context.Context, request resource.ConfigureRequest, _ *resource.ConfigureResponse) {
	if request.ProviderData == nil {
		return
	}

	c.client = request.ProviderData.(api.Client)
}

func (c *ClickPipeResource) Metadata(_ context.Context, request resource.MetadataRequest, response *resource.MetadataResponse) {
	response.TypeName = request.ProviderTypeName + "_clickpipe"
}

func (c *ClickPipeResource) Schema(_ context.Context, _ resource.SchemaRequest, response *resource.SchemaResponse) {
	wrapStringsWithBackticksAndJoinCommaSeparated := func(s []string) string {
		wrapped := make([]string, len(s))
		for i, v := range s {
			wrapped[i] = "`" + v + "`"
		}
		return strings.Join(wrapped, ", ")
	}

	response.Schema = schema.Schema{
		MarkdownDescription: clickPipeResourceDescription,
		Attributes: map[string]schema.Attribute{
			"id": schema.StringAttribute{
				Description: "The ID of the ClickPipe. Generated by the ClickHouse Cloud.",
				Computed:    true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.UseStateForUnknown(),
				},
			},
			"service_id": schema.StringAttribute{
				Description: "The ID of the service to which the ClickPipe belongs.",
				Required:    true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.RequiresReplace(),
				},
			},
			"name": schema.StringAttribute{
				Description: "The name of the ClickPipe.",
				Required:    true,
			},
			"scaling": schema.SingleNestedAttribute{
				Attributes: map[string]schema.Attribute{
					"replicas": schema.Int64Attribute{
						Description: "The number of desired replicas for the ClickPipe. Default is 1. The maximum value is 10.",
						Optional:    true,
						Computed:    true,
						Default:     int64default.StaticInt64(1),
						Validators: []validator.Int64{
							int64validator.Between(1, 10),
						},
					},
					"replica_cpu_millicores": schema.Int64Attribute{
						Description: "The CPU allocation per replica in millicores. Must be between 125 and 2000.",
						Optional:    true,
						Computed:    true,
						Validators: []validator.Int64{
							int64validator.Between(125, 2000),
						},
					},
					"replica_memory_gb": schema.Float64Attribute{
						Description: "The memory allocation per replica in GB. Must be between 0.5 and 8.0.",
						Optional:    true,
						Computed:    true,
						Validators: []validator.Float64{
							float64validator.Between(0.5, 8.0),
						},
					},
				},
				Optional: true,
				Computed: true,
			},
			"state": schema.StringAttribute{
				MarkdownDescription: "The desired state of the ClickPipe. (`Running`, `Stopped`). Default is `Running`.",
				Optional:            true,
				Default:             stringdefault.StaticString(api.ClickPipeRunningState),
				Computed:            true,
				Validators: []validator.String{
					stringvalidator.OneOf(api.ClickPipeRunningState, api.ClickPipeStoppedState),
				},
			},
			"source": schema.SingleNestedAttribute{
				Description: "The data source for the ClickPipe. At least one source configuration must be provided.",
				Attributes: map[string]schema.Attribute{
					"kafka": schema.SingleNestedAttribute{
						MarkdownDescription: "The Kafka source configuration for the ClickPipe.",
						Optional:            true,
						Attributes: map[string]schema.Attribute{
							"type": schema.StringAttribute{
								MarkdownDescription: fmt.Sprintf(
									"The type of the Kafka source. (%s). Default is `%s`.",
									wrapStringsWithBackticksAndJoinCommaSeparated(api.ClickPipeKafkaSourceTypes),
									api.ClickPipeKafkaSourceType,
								),
								Computed: true,
								Optional: true,
								Default:  stringdefault.StaticString(api.ClickPipeKafkaSourceType),
								Validators: []validator.String{
									stringvalidator.OneOf(api.ClickPipeKafkaSourceTypes...),
								},
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
							"format": schema.StringAttribute{
								MarkdownDescription: fmt.Sprintf(
									"The format of the Kafka source. (%s)",
									wrapStringsWithBackticksAndJoinCommaSeparated(api.ClickPipeKafkaFormats),
								),
								Required: true,
								Validators: []validator.String{
									stringvalidator.OneOf(api.ClickPipeKafkaFormats...),
								},
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
							"brokers": schema.StringAttribute{
								Description: "The list of Kafka bootstrap brokers. (comma separated)",
								Required:    true,
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
							"topics": schema.StringAttribute{
								Description: "The list of Kafka topics. (comma separated)",
								Required:    true,
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
							"consumer_group": schema.StringAttribute{
								MarkdownDescription: "Consumer group of the Kafka source. If not provided `clickpipes-<ID>` will be used.",
								Computed:            true,
								Optional:            true,
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.UseStateForUnknown(),
									stringplanmodifier.RequiresReplace(),
								},
							},
							"offset": schema.SingleNestedAttribute{
								MarkdownDescription: "The Kafka offset.",
								Optional:            true,
								Attributes: map[string]schema.Attribute{
									"strategy": schema.StringAttribute{
										MarkdownDescription: fmt.Sprintf(
											"The offset strategy for the Kafka source. (%s)",
											wrapStringsWithBackticksAndJoinCommaSeparated(api.ClickPipeKafkaOffsetStrategies),
										),
										Required: true,
										Validators: []validator.String{
											stringvalidator.OneOf(api.ClickPipeKafkaOffsetStrategies...),
										},
									},
									"timestamp": schema.StringAttribute{
										MarkdownDescription: fmt.Sprintf(
											"The timestamp for the Kafka offset. Use with `%s` offset strategy. (format `2021-01-01T00:00`)",
											api.ClickPipeKafkaOffsetFromTimestampStrategy,
										),
										Optional: true,
									},
								},
								PlanModifiers: []planmodifier.Object{
									objectplanmodifier.RequiresReplace(),
								},
							},
							"schema_registry": schema.SingleNestedAttribute{
								MarkdownDescription: "The schema registry for the Kafka source.",
								Optional:            true,
								Attributes: map[string]schema.Attribute{
									"url": schema.StringAttribute{
										Description: "The URL of the schema registry.",
										Required:    true,
									},
									"authentication": schema.StringAttribute{
										Description: "The authentication method for the Schema Registry. Only supported is `PLAIN`.",
										Required:    true,
										Validators: []validator.String{
											stringvalidator.OneOf("PLAIN"),
										},
									},
									"credentials": schema.SingleNestedAttribute{
										MarkdownDescription: "The credentials for the Schema Registry.",
										Required:            true,
										Attributes: map[string]schema.Attribute{
											"username": schema.StringAttribute{
												Description: "The username for the Schema Registry.",
												Required:    true,
												Sensitive:   true,
											},
											"password": schema.StringAttribute{
												Description: "The password for the Schema Registry.",
												Required:    true,
												Sensitive:   true,
											},
										},
									},
								},
								PlanModifiers: []planmodifier.Object{
									objectplanmodifier.RequiresReplace(),
								},
							},
							"authentication": schema.StringAttribute{
								MarkdownDescription: fmt.Sprintf(
									"The authentication method for the Kafka source. (%s). Default is `%s`.",
									wrapStringsWithBackticksAndJoinCommaSeparated(api.ClickPipeKafkaAuthenticationMethods),
									api.ClickPipeKafkaAuthenticationPlain,
								),
								Computed: true,
								Optional: true,
								Default:  stringdefault.StaticString("PLAIN"),
								Validators: []validator.String{
									stringvalidator.OneOf(api.ClickPipeKafkaAuthenticationMethods...),
								},
							},
							"credentials": schema.SingleNestedAttribute{
								MarkdownDescription: "The credentials for the Kafka source.",
								Attributes: map[string]schema.Attribute{
									"username": schema.StringAttribute{
										Description: "The username for the Kafka source.",
										Optional:    true,
										Sensitive:   true,
									},
									"password": schema.StringAttribute{
										Description: "The password for the Kafka source.",
										Optional:    true,
										Sensitive:   true,
									},
									"access_key_id": schema.StringAttribute{
										Description: "The access key ID for the Kafka source. Use with `IAM_USER` authentication.",
										Optional:    true,
										Sensitive:   true,
									},
									"secret_key": schema.StringAttribute{
										Description: "The secret key for the Kafka source. Use with `IAM_USER` authentication.",
										Optional:    true,
										Sensitive:   true,
									},
									"connection_string": schema.StringAttribute{
										Description: "The connection string for the Kafka source. Use with `azureeventhub` Kafka source type. Use with `PLAIN` authentication.",
										Optional:    true,
										Sensitive:   true,
									},
								},
								Optional: true,
							},
							"iam_role": schema.StringAttribute{
								MarkdownDescription: "The IAM role for the Kafka source. Use with `IAM_ROLE` authentication. It can be used with AWS ClickHouse service only. Read more in [ClickPipes documentation page](https://clickhouse.com/docs/en/integrations/clickpipes/kafka#iam)",
								Optional:            true,
							},
							"ca_certificate": schema.StringAttribute{
								MarkdownDescription: "PEM encoded CA certificates to validate the broker's certificate.",
								Optional:            true,
							},
							"reverse_private_endpoint_ids": schema.ListAttribute{
								MarkdownDescription: "The list of reverse private endpoint IDs for the Kafka source. (comma separated)",
								Optional:            true,
								ElementType:         types.StringType,
								PlanModifiers: []planmodifier.List{
									listplanmodifier.RequiresReplace(),
								},
							},
						},
					},
					"object_storage": schema.SingleNestedAttribute{
						MarkdownDescription: "The compatible object storage source configuration for the ClickPipe.",
						Optional:            true,
						Attributes: map[string]schema.Attribute{
							"type": schema.StringAttribute{
								MarkdownDescription: fmt.Sprintf(
									"The type of the S3-compatbile source (%s). Default is `%s`.",
									wrapStringsWithBackticksAndJoinCommaSeparated(api.ClickPipeObjectStorageTypes),
									api.ClickPipeObjectStorageS3Type,
								),
								Computed: true,
								Optional: true,
								Default:  stringdefault.StaticString(api.ClickPipeObjectStorageS3Type),
								Validators: []validator.String{
									stringvalidator.OneOf(api.ClickPipeObjectStorageTypes...),
								},
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
							"format": schema.StringAttribute{
								MarkdownDescription: fmt.Sprintf(
									"The format of the S3 objects. (%s)",
									wrapStringsWithBackticksAndJoinCommaSeparated(api.ClickPipeObjectStorageFormats),
								),
								Required: true,
								Validators: []validator.String{
									stringvalidator.OneOf(api.ClickPipeObjectStorageFormats...),
								},
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
							"url": schema.StringAttribute{
								MarkdownDescription: "The URL of the S3/GCS bucket. Required for S3 and GCS types. Not used for Azure Blob Storage (use path and azure_container_name instead). You can specify multiple files using bash-like wildcards. For more information, see the documentation on using wildcards in path: https://clickhouse.com/docs/en/integrations/clickpipes/object-storage#limitations",
								Optional:            true,
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
							"delimiter": schema.StringAttribute{
								MarkdownDescription: "The delimiter for the S3 source. Default is `,`.",
								Optional:            true,
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
							"compression": schema.StringAttribute{
								MarkdownDescription: fmt.Sprintf(
									"Compression algorithm used for the files.. (%s)",
									wrapStringsWithBackticksAndJoinCommaSeparated(api.ClickPipeObjectStorageCompressions),
								),
								Optional: true,
								Validators: []validator.String{
									stringvalidator.OneOf(api.ClickPipeObjectStorageCompressions...),
								},
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
							"is_continuous": schema.BoolAttribute{
								MarkdownDescription: "If set to true, the pipe will continuously read new files from the source. If set to false, the pipe will read the files only once. New files have to be uploaded lexically order.",
								Optional:            true,
								Computed:            true,
								Default:             booldefault.StaticBool(false),
								PlanModifiers: []planmodifier.Bool{
									boolplanmodifier.RequiresReplace(),
								},
							},
							"authentication": schema.StringAttribute{
								MarkdownDescription: "CONNECTION_STRING is for Azure Blob Storage. IAM_ROLE and IAM_USER are for AWS S3/GCS/DigitalOcean. If not provided, no authentication is used",
								Optional:            true,
								Validators: []validator.String{
									stringvalidator.OneOf(api.ClickPipeObjectStorageAuthenticationMethods...),
								},
							},
							"access_key": schema.SingleNestedAttribute{
								MarkdownDescription: "Access key",
								Optional:            true,
								Attributes: map[string]schema.Attribute{
									"access_key_id": schema.StringAttribute{
										Description: "The access key ID for the S3 source. Use with `IAM_USER` authentication.",
										Optional:    true,
										Sensitive:   true,
									},
									"secret_key": schema.StringAttribute{
										Description: "The secret key for the S3 source. Use with `IAM_USER` authentication.",
										Optional:    true,
										Sensitive:   true,
									},
								},
							},
							"iam_role": schema.StringAttribute{
								MarkdownDescription: "The IAM role for the S3 source. Use with `IAM_ROLE` authentication. It can be used with AWS ClickHouse service only. Read more in [ClickPipes documentation page](https://clickhouse.com/docs/en/integrations/clickpipes/object-storage#authentication)",
								Optional:            true,
							},
							"connection_string": schema.StringAttribute{
								MarkdownDescription: "Connection string for Azure Blob Storage authentication. Required when authentication is CONNECTION_STRING. Example: `DefaultEndpointsProtocol=https;AccountName=myaccount;AccountKey=mykey;EndpointSuffix=core.windows.net`",
								Optional:            true,
								Sensitive:           true,
							},
							"path": schema.StringAttribute{
								MarkdownDescription: "Path to the file(s) within the Azure container. Used for Azure Blob Storage sources. You can specify multiple files using bash-like wildcards. For more information, see the documentation on using wildcards in path: https://clickhouse.com/docs/en/integrations/clickpipes/object-storage#limitations. Example: `data/logs/*.json`",
								Optional:            true,
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
							"azure_container_name": schema.StringAttribute{
								MarkdownDescription: "Container name for Azure Blob Storage. Required when type is azureblobstorage. Example: `mycontainer`",
								Optional:            true,
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
						},
						PlanModifiers: []planmodifier.Object{
							objectplanmodifier.RequiresReplace(),
						},
					},
					"kinesis": schema.SingleNestedAttribute{
						MarkdownDescription: "The Kinesis source configuration for the ClickPipe.",
						Optional:            true,
						Attributes: map[string]schema.Attribute{
							"format": schema.StringAttribute{
								MarkdownDescription: fmt.Sprintf(
									"The format of the Kinesis source. (%s)",
									wrapStringsWithBackticksAndJoinCommaSeparated(api.ClickPipeKinesisFormats),
								),
								Required: true,
								Validators: []validator.String{
									stringvalidator.OneOf(api.ClickPipeKinesisFormats...),
								},
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
							"stream_name": schema.StringAttribute{
								Description: "The name of the Kinesis stream.",
								Required:    true,
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
							"region": schema.StringAttribute{
								Description: "The AWS region of the Kinesis stream.",
								Required:    true,
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
							"iterator_type": schema.StringAttribute{
								MarkdownDescription: fmt.Sprintf(
									"The iterator type for the Kinesis source. (%s)",
									wrapStringsWithBackticksAndJoinCommaSeparated(api.ClickPipeKinesisIteratorTypes),
								),
								Required: true,
								Validators: []validator.String{
									stringvalidator.OneOf(api.ClickPipeKinesisIteratorTypes...),
								},
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
							"timestamp": schema.StringAttribute{
								MarkdownDescription: fmt.Sprintf(
									"The timestamp for the Kinesis source. Use with `%s` iterator type. (format `2021-01-01T00:00`)",
									api.ClickPipeKinesisAtTimestampIteratorType,
								),
								Optional: true,
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
							"use_enhanced_fan_out": schema.BoolAttribute{
								Description: "Whether to use enhanced fan-out consumer.",
								Optional:    true,
								Computed:    true,
								Default:     booldefault.StaticBool(false),
								PlanModifiers: []planmodifier.Bool{
									boolplanmodifier.RequiresReplace(),
								},
							},
							"authentication": schema.StringAttribute{
								MarkdownDescription: fmt.Sprintf(
									"The authentication method for the Kinesis source. (%s).",
									wrapStringsWithBackticksAndJoinCommaSeparated(api.ClickPipeKinesisAuthenticationMethods),
								),
								Required: true,
								Validators: []validator.String{
									stringvalidator.OneOf(api.ClickPipeKinesisAuthenticationMethods...),
								},
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
							"access_key": schema.SingleNestedAttribute{
								MarkdownDescription: "The access key for the Kinesis source. Use with `IAM_USER` authentication.",
								Optional:            true,
								Attributes: map[string]schema.Attribute{
									"access_key_id": schema.StringAttribute{
										Description: "The access key ID for the Kinesis source.",
										Required:    true,
										Sensitive:   true,
									},
									"secret_key": schema.StringAttribute{
										Description: "The secret key for the Kinesis source.",
										Required:    true,
										Sensitive:   true,
									},
								},
								PlanModifiers: []planmodifier.Object{
									objectplanmodifier.RequiresReplace(),
								},
							},
							"iam_role": schema.StringAttribute{
								MarkdownDescription: "The IAM role for the Kinesis source. Use with `IAM_ROLE` authentication. It can be used with AWS ClickHouse service only. Read more in [ClickPipes documentation page](https://clickhouse.com/docs/en/integrations/clickpipes/kinesis).",
								Optional:            true,
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
						},
					},
				},
				Required: true,
			},
			"destination": schema.SingleNestedAttribute{
				Description: "The destination for the ClickPipe.",
				Attributes: map[string]schema.Attribute{
					"database": schema.StringAttribute{
						MarkdownDescription: "The name of the ClickHouse database. Default is `default`.",
						Default:             stringdefault.StaticString("default"),
						Computed:            true,
						Optional:            true,
						PlanModifiers: []planmodifier.String{
							stringplanmodifier.RequiresReplace(),
						},
					},
					"table": schema.StringAttribute{
						Description: "The name of the ClickHouse table.",
						Required:    true,
						PlanModifiers: []planmodifier.String{
							stringplanmodifier.RequiresReplace(),
						},
					},
					"managed_table": schema.BoolAttribute{
						MarkdownDescription: "Whether the table is managed by ClickHouse Cloud. If `false`, the table must exist in the database. Default is `true`.",
						Default:             booldefault.StaticBool(true),
						Computed:            true,
						Optional:            true,
						PlanModifiers: []planmodifier.Bool{
							boolplanmodifier.RequiresReplace(),
						},
					},
					"table_definition": schema.SingleNestedAttribute{
						MarkdownDescription: "Definition of the destination table. Required for ClickPipes managed tables.",
						Optional:            true,
						Attributes: map[string]schema.Attribute{
							"engine": schema.SingleNestedAttribute{
								MarkdownDescription: "The engine of the ClickHouse table.",
								Required:            true,
								Attributes: map[string]schema.Attribute{
									"type": schema.StringAttribute{
										MarkdownDescription: "The type of the engine. Only `MergeTree` is supported.",
										Required:            true,
										Validators: []validator.String{
											stringvalidator.OneOf("MergeTree"),
										},
									},
								},
							},
							"sorting_key": schema.ListAttribute{
								MarkdownDescription: "The list of columns for the sorting key.",
								Optional:            true,
								ElementType:         types.StringType,
							},
							"partition_by": schema.StringAttribute{
								MarkdownDescription: "The column to partition the table by.",
								Optional:            true,
							},
							"primary_key": schema.StringAttribute{
								MarkdownDescription: "The primary key of the table.",
								Optional:            true,
							},
						},
						PlanModifiers: []planmodifier.Object{
							objectplanmodifier.RequiresReplace(),
						},
					},
					"columns": schema.ListNestedAttribute{
						Description: "The list of columns for the ClickHouse table.",
						NestedObject: schema.NestedAttributeObject{
							Attributes: map[string]schema.Attribute{
								"name": schema.StringAttribute{
									Description: "The name of the column.",
									Required:    true,
								},
								"type": schema.StringAttribute{
									Description: "The type of the column.",
									Required:    true,
								},
							},
						},
						Required: true,
					},
					"roles": schema.ListAttribute{
						MarkdownDescription: "ClickPipe will create a ClickHouse user with these roles. Add your custom roles here if required.",
						ElementType:         types.StringType,
						Optional:            true,
						PlanModifiers: []planmodifier.List{
							listplanmodifier.RequiresReplace(),
						},
					},
				},
				Required: true,
			},
			"field_mappings": schema.ListNestedAttribute{
				Description: "Field mapping between source and destination table.",
				Optional:    true,
				NestedObject: schema.NestedAttributeObject{
					Attributes: map[string]schema.Attribute{
						"source_field": schema.StringAttribute{
							Description: "The name of the source field.",
							Required:    true,
						},
						"destination_field": schema.StringAttribute{
							Description: "The name of the column in destination table.",
							Required:    true,
						},
					},
				},
			},
			"settings": schema.DynamicAttribute{
				Description: "Advanced configuration options for the ClickPipe. These settings are specific to each pipe. For the complete list of available options, see the [OpenAPI documentation](https://clickhouse.com/docs/cloud/manage/api/swagger)",
				Optional:    true,
			},
		},
	}
}

func (c *ClickPipeResource) ModifyPlan(ctx context.Context, request resource.ModifyPlanRequest, response *resource.ModifyPlanResponse) {
	if request.Plan.Raw.IsNull() {
		// If the entire plan is null, the resource is planned for destruction.
		// This logic is buggy. Plan should be null for destruction, but in fact contains a state/config.
		// Checked with Terraform v1.15 and v1.5. Thus, `Completed` state is checked explicit in Update method.
		return
	}

	var plan, state, config models.ClickPipeResourceModel
	response.Diagnostics.Append(request.Plan.Get(ctx, &plan)...)
	if !request.State.Raw.IsNull() {
		response.Diagnostics.Append(request.State.Get(ctx, &state)...)
	}
	if !request.Config.Raw.IsNull() {
		response.Diagnostics.Append(request.Config.Get(ctx, &config)...)
	}
}

func (c *ClickPipeResource) Create(ctx context.Context, request resource.CreateRequest, response *resource.CreateResponse) {
	var plan models.ClickPipeResourceModel
	diags := request.Plan.Get(ctx, &plan)
	response.Diagnostics.Append(diags...)
	if response.Diagnostics.HasError() {
		return
	}

	serviceID := plan.ServiceID.ValueString()

	clickPipe := api.ClickPipe{
		Name: plan.Name.ValueString(),
	}

	if source := c.extractSourceFromPlan(ctx, response.Diagnostics, plan, false); source != nil {
		clickPipe.Source = *source
	} else {
		return
	}

	destinationModel := models.ClickPipeDestinationModel{}
	response.Diagnostics.Append(plan.Destination.As(ctx, &destinationModel, basetypes.ObjectAsOptions{})...)
	destinationColumnsModels := make([]models.ClickPipeDestinationColumnModel, len(destinationModel.Columns.Elements()))
	response.Diagnostics.Append(destinationModel.Columns.ElementsAs(ctx, &destinationColumnsModels, false)...)

	// Extract roles from the destination model
	var rolesSlice []string
	if !destinationModel.Roles.IsNull() && len(destinationModel.Roles.Elements()) > 0 {
		rolesSlice = make([]string, len(destinationModel.Roles.Elements()))
		response.Diagnostics.Append(destinationModel.Roles.ElementsAs(ctx, &rolesSlice, false)...)
	}

	clickPipe.Destination = api.ClickPipeDestination{
		Database:     destinationModel.Database.ValueString(),
		Table:        destinationModel.Table.ValueString(),
		ManagedTable: destinationModel.ManagedTable.ValueBool(),
		Columns:      make([]api.ClickPipeDestinationColumn, len(destinationColumnsModels)),
		Roles:        rolesSlice,
	}

	if destinationModel.ManagedTable.ValueBool() {
		if destinationModel.TableDefinition.IsNull() {
			response.Diagnostics.AddError(
				"Error Creating ClickPipe",
				"Managed table requires table definition",
			)
			return
		}

		tableDefinitionModel := models.ClickPipeDestinationTableDefinitionModel{}
		response.Diagnostics.Append(destinationModel.TableDefinition.As(ctx, &tableDefinitionModel, basetypes.ObjectAsOptions{})...)

		sortingKey := make([]string, len(tableDefinitionModel.SortingKey.Elements()))

		for i, sortingKeyModel := range tableDefinitionModel.SortingKey.Elements() {
			sortingKey[i] = sortingKeyModel.(types.String).ValueString()
		}

		tableEngineModel := models.ClickPipeDestinationTableEngineModel{}
		response.Diagnostics.Append(tableDefinitionModel.Engine.As(ctx, &tableEngineModel, basetypes.ObjectAsOptions{})...)

		clickPipe.Destination.TableDefinition = &api.ClickPipeDestinationTableDefinition{
			Engine:      api.ClickPipeDestinationTableEngine{Type: tableEngineModel.Type.ValueString()},
			PartitionBy: tableDefinitionModel.PartitionBy.ValueStringPointer(),
			PrimaryKey:  tableDefinitionModel.PrimaryKey.ValueStringPointer(),
			SortingKey:  sortingKey,
		}
	}

	for i, columnModel := range destinationColumnsModels {
		clickPipe.Destination.Columns[i] = api.ClickPipeDestinationColumn{
			Name: columnModel.Name.ValueString(),
			Type: columnModel.Type.ValueString(),
		}
	}

	fieldMappingsModels := make([]models.ClickPipeFieldMappingModel, len(plan.FieldMappings.Elements()))
	response.Diagnostics.Append(plan.FieldMappings.ElementsAs(ctx, &fieldMappingsModels, false)...)
	clickPipe.FieldMappings = make([]api.ClickPipeFieldMapping, len(fieldMappingsModels))
	for i, fieldMappingModel := range fieldMappingsModels {
		clickPipe.FieldMappings[i] = api.ClickPipeFieldMapping{
			SourceField:      fieldMappingModel.SourceField.ValueString(),
			DestinationField: fieldMappingModel.DestinationField.ValueString(),
		}
	}

	// Handle settings
	if !plan.Settings.IsNull() && !plan.Settings.IsUnknown() {
		settingsMap := make(map[string]any)
		underlyingValue := plan.Settings.UnderlyingValue()

		// Settings should be an object/map at the top level
		if objValue, ok := underlyingValue.(types.Object); ok {
			for key, value := range objValue.Attributes() {
				settingsMap[key] = utils.ConvertTerraformValueToJSON(value)
			}
		}

		if len(settingsMap) > 0 {
			clickPipe.Settings = settingsMap
		}
	}

	createdClickPipe, err := c.client.CreateClickPipe(ctx, serviceID, clickPipe)
	if err != nil {
		response.Diagnostics.AddError(
			"Error Creating ClickPipe",
			"Could not create ClickPipe, unexpected error: "+err.Error(),
		)
		return
	}

	if !plan.Scaling.IsUnknown() && !plan.Scaling.IsNull() {
		scalingModel := models.ClickPipeScalingModel{}
		response.Diagnostics.Append(plan.Scaling.As(ctx, &scalingModel, basetypes.ObjectAsOptions{})...)

		var desiredReplicas *int64
		var desiredCpuMillicores *int64
		var desiredMemoryGb *float64
		needsScaling := false

		if !scalingModel.Replicas.IsUnknown() && !scalingModel.Replicas.IsNull() &&
			(createdClickPipe.Scaling == nil || createdClickPipe.Scaling.Replicas == nil ||
				*createdClickPipe.Scaling.Replicas != scalingModel.Replicas.ValueInt64()) {
			desiredReplicas = scalingModel.Replicas.ValueInt64Pointer()
			needsScaling = true
		}

		if !scalingModel.ReplicaCpuMillicores.IsUnknown() && !scalingModel.ReplicaCpuMillicores.IsNull() &&
			(createdClickPipe.Scaling == nil || createdClickPipe.Scaling.GetCpuMillicores() == nil ||
				*createdClickPipe.Scaling.GetCpuMillicores() != scalingModel.ReplicaCpuMillicores.ValueInt64()) {
			desiredCpuMillicores = scalingModel.ReplicaCpuMillicores.ValueInt64Pointer()
			needsScaling = true
		}

		if !scalingModel.ReplicaMemoryGb.IsUnknown() && !scalingModel.ReplicaMemoryGb.IsNull() &&
			(createdClickPipe.Scaling == nil || createdClickPipe.Scaling.GetMemoryGb() == nil ||
				*createdClickPipe.Scaling.GetMemoryGb() != scalingModel.ReplicaMemoryGb.ValueFloat64()) {
			desiredMemoryGb = scalingModel.ReplicaMemoryGb.ValueFloat64Pointer()
			needsScaling = true
		}

		if needsScaling {
			scalingRequest := api.ClickPipeScalingRequest{
				Replicas:             desiredReplicas,
				ReplicaCpuMillicores: desiredCpuMillicores,
				ReplicaMemoryGb:      desiredMemoryGb,
			}

			if createdClickPipe, err = c.client.ScalingClickPipe(ctx, serviceID, createdClickPipe.ID, scalingRequest); err != nil {
				response.Diagnostics.AddError(
					"Error Scaling ClickPipe",
					"Could not scale ClickPipe, unexpected error: "+err.Error(),
				)
				return
			}
		}
	}

	if plan.State.ValueString() == api.ClickPipeStoppedState {
		if _, err := c.client.ChangeClickPipeState(ctx, serviceID, createdClickPipe.ID, api.ClickPipeStateStop); err != nil {
			response.Diagnostics.AddError(
				"Error Stopping ClickPipe",
				"Could not stop ClickPipe, unexpected error: "+err.Error(),
			)
			return
		}
	}

	if _, err := c.client.WaitForClickPipeState(ctx, serviceID, createdClickPipe.ID, func(state string) bool {
		return state == plan.State.ValueString() // we expect the state to be the same as planned: "Running" or "Stopped"
	}, clickPipeStateChangeMaxWaitSeconds); err != nil {
		response.Diagnostics.AddWarning(
			"ClickPipe didn't reach the desired state",
			err.Error(),
		)
	}

	plan.ID = types.StringValue(createdClickPipe.ID)

	if err := c.syncClickPipeState(ctx, &plan); err != nil {
		response.Diagnostics.AddError(
			"Error reading ClickPipe",
			"Could not read ClickPipe, unexpected error: "+err.Error(),
		)
		return
	}

	diags = response.State.Set(ctx, plan)
	response.Diagnostics.Append(diags...)
}

func (c *ClickPipeResource) extractSourceFromPlan(ctx context.Context, diagnostics diag.Diagnostics, plan models.ClickPipeResourceModel, isUpdate bool) *api.ClickPipeSource {
	source := &api.ClickPipeSource{}

	sourceModel := models.ClickPipeSourceModel{}
	diagnostics.Append(plan.Source.As(ctx, &sourceModel, basetypes.ObjectAsOptions{})...)

	if !sourceModel.Kafka.IsNull() {
		kafkaModel := models.ClickPipeKafkaSourceModel{}
		diagnostics.Append(sourceModel.Kafka.As(ctx, &kafkaModel, basetypes.ObjectAsOptions{})...)

		var consumerGroup *string
		if !kafkaModel.ConsumerGroup.IsUnknown() {
			consumerGroup = kafkaModel.ConsumerGroup.ValueStringPointer()
		}

		source.Kafka = &api.ClickPipeKafkaSource{
			Brokers:        kafkaModel.Brokers.ValueString(),
			Topics:         kafkaModel.Topics.ValueString(),
			ConsumerGroup:  consumerGroup,
			Authentication: kafkaModel.Authentication.ValueString(),
			IAMRole:        kafkaModel.IAMRole.ValueStringPointer(),
			CACertificate:  kafkaModel.CACertificate.ValueStringPointer(),
		}

		if !isUpdate {
			source.Kafka.Type = kafkaModel.Type.ValueString()
			source.Kafka.Format = kafkaModel.Format.ValueString()
		}

		if kafkaModel.Authentication.ValueString() != api.ClickPipeAuthenticationIAMRole {
			if !kafkaModel.Credentials.IsNull() {
				credentialsModel := models.ClickPipeKafkaSourceCredentialsModel{}
				diagnostics.Append(kafkaModel.Credentials.As(ctx, &credentialsModel, basetypes.ObjectAsOptions{})...)

				var credentials *api.ClickPipeKafkaSourceCredentials

				if kafkaModel.Authentication.ValueString() != api.ClickPipeAuthenticationIAMRole {
					credentials = &api.ClickPipeKafkaSourceCredentials{}

					if !credentialsModel.Username.IsNull() && !credentialsModel.Password.IsNull() {
						credentials.ClickPipeSourceCredentials = &api.ClickPipeSourceCredentials{
							Username: credentialsModel.Username.ValueString(),
							Password: credentialsModel.Password.ValueString(),
						}
					} else if !credentialsModel.AccessKeyID.IsNull() && !credentialsModel.SecretKey.IsNull() {
						credentials.ClickPipeSourceAccessKey = &api.ClickPipeSourceAccessKey{
							AccessKeyID: credentialsModel.AccessKeyID.ValueString(),
							SecretKey:   credentialsModel.SecretKey.ValueString(),
						}
					} else if !credentialsModel.ConnectionString.IsNull() {
						credentials.ConnectionString = credentialsModel.ConnectionString.ValueStringPointer()
					} else {
						diagnostics.AddError(
							"Error Creating ClickPipe",
							"Kafka source requires credentials",
						)
						return nil
					}
				}

				source.Kafka.Credentials = credentials
			} else {
				diagnostics.AddError(
					"Error Creating ClickPipe",
					"Kafka source requires credentials",
				)
				return nil
			}
		}

		if !kafkaModel.SchemaRegistry.IsNull() {
			schemaRegistryModel := models.ClickPipeKafkaSchemaRegistryModel{}
			diagnostics.Append(kafkaModel.SchemaRegistry.As(ctx, &schemaRegistryModel, basetypes.ObjectAsOptions{})...)
			credentialsModel := models.ClickPipeSourceCredentialsModel{}
			diagnostics.Append(schemaRegistryModel.Credentials.As(ctx, &credentialsModel, basetypes.ObjectAsOptions{})...)

			source.Kafka.SchemaRegistry = &api.ClickPipeKafkaSchemaRegistry{
				URL:            schemaRegistryModel.URL.ValueString(),
				Authentication: schemaRegistryModel.Authentication.ValueString(),
				Credentials: &api.ClickPipeSourceCredentials{
					Username: credentialsModel.Username.ValueString(),
					Password: credentialsModel.Password.ValueString(),
				},
			}
		}

		if !kafkaModel.Offset.IsNull() {
			offsetModel := models.ClickPipeKafkaOffsetModel{}
			diagnostics.Append(kafkaModel.Offset.As(ctx, &offsetModel, basetypes.ObjectAsOptions{})...)

			var timestamp *string
			if !offsetModel.Timestamp.IsUnknown() {
				timestamp = offsetModel.Timestamp.ValueStringPointer()
			}

			source.Kafka.Offset = &api.ClickPipeKafkaOffset{
				Strategy:  offsetModel.Strategy.ValueString(),
				Timestamp: timestamp,
			}
		}

		if !kafkaModel.ReversePrivateEndpointIDs.IsNull() {
			reversePrivateEndpointIDs := make([]string, len(kafkaModel.ReversePrivateEndpointIDs.Elements()))
			diagnostics.Append(kafkaModel.ReversePrivateEndpointIDs.ElementsAs(ctx, &reversePrivateEndpointIDs, false)...)
			source.Kafka.ReversePrivateEndpointIDs = reversePrivateEndpointIDs
		}
	} else if !sourceModel.ObjectStorage.IsNull() {
		objectStorageModel := models.ClickPipeObjectStorageSourceModel{}

		diagnostics.Append(sourceModel.ObjectStorage.As(ctx, &objectStorageModel, basetypes.ObjectAsOptions{})...)

		var accessKey *api.ClickPipeSourceAccessKey
		if !objectStorageModel.AccessKey.IsUnknown() && !objectStorageModel.AccessKey.IsNull() {
			accessKeyModel := models.ClickPipeSourceAccessKeyModel{}
			diagnostics.Append(objectStorageModel.AccessKey.As(ctx, &accessKeyModel, basetypes.ObjectAsOptions{})...)

			accessKey = &api.ClickPipeSourceAccessKey{
				AccessKeyID: accessKeyModel.AccessKeyID.ValueString(),
				SecretKey:   accessKeyModel.SecretKey.ValueString(),
			}
		}

		storageType := objectStorageModel.Type.ValueString()
		if storageType == api.ClickPipeObjectStorageAzureBlobType {
			if !objectStorageModel.URL.IsNull() && !objectStorageModel.URL.IsUnknown() && objectStorageModel.URL.ValueString() != "" {
				diagnostics.AddError(
					"Error Creating ClickPipe",
					"URL field should not be used with Azure Blob Storage. Use 'path' and 'azure_container_name' fields instead",
				)
				return nil
			}

			if objectStorageModel.AzureContainerName.IsNull() || objectStorageModel.AzureContainerName.IsUnknown() || objectStorageModel.AzureContainerName.ValueString() == "" {
				diagnostics.AddError(
					"Error Creating ClickPipe",
					"azure_container_name is required when using Azure Blob Storage",
				)
				return nil
			}

			if objectStorageModel.ConnectionString.IsNull() || objectStorageModel.ConnectionString.IsUnknown() || objectStorageModel.ConnectionString.ValueString() == "" {
				diagnostics.AddError(
					"Error Creating ClickPipe",
					"connection_string is required when using Azure Blob Storage",
				)
				return nil
			}
		} else {
			if objectStorageModel.URL.IsNull() || objectStorageModel.URL.IsUnknown() || objectStorageModel.URL.ValueString() == "" {
				diagnostics.AddError(
					"Error Creating ClickPipe",
					fmt.Sprintf("URL is required when using %s storage type", storageType),
				)
				return nil
			}
		}

		objectStorage := &api.ClickPipeObjectStorageSource{
			Type:           objectStorageModel.Type.ValueString(),
			Format:         objectStorageModel.Format.ValueString(),
			Delimiter:      objectStorageModel.Delimiter.ValueStringPointer(),
			Compression:    objectStorageModel.Compression.ValueStringPointer(),
			IsContinuous:   objectStorageModel.IsContinuous.ValueBool(),
			Authentication: objectStorageModel.Authentication.ValueStringPointer(),
			AccessKey:      accessKey,
			IAMRole:        objectStorageModel.IAMRole.ValueStringPointer(),
		}

		if storageType == api.ClickPipeObjectStorageAzureBlobType {
			objectStorage.ConnectionString = objectStorageModel.ConnectionString.ValueStringPointer()
			objectStorage.Path = objectStorageModel.Path.ValueStringPointer()
			objectStorage.AzureContainerName = objectStorageModel.AzureContainerName.ValueStringPointer()
		} else {
			objectStorage.URL = objectStorageModel.URL.ValueString()
		}

		source.ObjectStorage = objectStorage
	} else if !sourceModel.Kinesis.IsNull() {
		kinesisModel := models.ClickPipeKinesisSourceModel{}
		diagnostics.Append(sourceModel.Kinesis.As(ctx, &kinesisModel, basetypes.ObjectAsOptions{})...)

		source.Kinesis = &api.ClickPipeKinesisSource{
			Format:            kinesisModel.Format.ValueString(),
			StreamName:        kinesisModel.StreamName.ValueString(),
			Region:            kinesisModel.Region.ValueString(),
			IteratorType:      kinesisModel.IteratorType.ValueString(),
			UseEnhancedFanOut: kinesisModel.UseEnhancedFanOut.ValueBool(),
			Authentication:    kinesisModel.Authentication.ValueString(),
			IAMRole:           kinesisModel.IAMRole.ValueStringPointer(),
		}

		if !kinesisModel.Timestamp.IsNull() {
			source.Kinesis.Timestamp = kinesisModel.Timestamp.ValueStringPointer()
		}

		if kinesisModel.Authentication.ValueString() == api.ClickPipeAuthenticationIAMUser {
			if !kinesisModel.AccessKey.IsNull() {
				accessKeyModel := models.ClickPipeSourceAccessKeyModel{}
				diagnostics.Append(kinesisModel.AccessKey.As(ctx, &accessKeyModel, basetypes.ObjectAsOptions{})...)

				source.Kinesis.AccessKey = &api.ClickPipeSourceAccessKey{
					AccessKeyID: accessKeyModel.AccessKeyID.ValueString(),
					SecretKey:   accessKeyModel.SecretKey.ValueString(),
				}
			} else {
				diagnostics.AddError(
					"Error Creating ClickPipe",
					"Kinesis source with IAM_USER authentication requires access_key",
				)
				return nil
			}
		}
	} else {
		diagnostics.AddError(
			"Error Creating ClickPipe",
			"ClickPipe requires at least one source configuration",
		)
		return nil
	}

	return source
}

func (c *ClickPipeResource) syncClickPipeState(ctx context.Context, state *models.ClickPipeResourceModel) error {
	if state.ID.IsNull() {
		return fmt.Errorf("ClickPipe ID is required to sync state")
	}

	clickPipe, err := c.client.GetClickPipe(ctx, state.ServiceID.ValueString(), state.ID.ValueString())
	if api.IsNotFound(err) {
		// ClickPipe does not exist, deleted outside Terraform
		state.ID = types.StringNull()
		return nil
	} else if err != nil {
		return err
	}

	state.ID = types.StringValue(clickPipe.ID)
	state.Name = types.StringValue(clickPipe.Name)

	// In case ClickPipe status is not as expected,
	// we should return an error that clearly states the issue so the user can take action.
	if clickPipe.State != state.State.ValueString() {
		if clickPipe.State == api.ClickPipeFailedState {
			return fmt.Errorf("ClickPipe is in a failed state: %s. Review the ClickPipe logs in the ClickHouse Cloud Console", clickPipe.State)
		}

		if clickPipe.State == api.ClickPipeInternalErrorState {
			return fmt.Errorf("ClickPipe is in an internal error state. Contact ClickHouse Cloud support for assistance")
		}

		if clickPipe.State == api.ClickPipeProvisioningState {
			// In usual scenarios, ClickPipe is in Provisioning after update/create operations.
			// After it should transit to a Running state.
			// We would like to avoid any plan errors when the ClickPipe is in Provisioning state.
			clickPipe.State = api.ClickPipeRunningState
		}
	}

	state.State = types.StringValue(clickPipe.State)

	// Only sync scaling if it was configured (not null)
	if !state.Scaling.IsNull() && clickPipe.Scaling != nil {
		cpuMillicores := clickPipe.Scaling.GetCpuMillicores()
		memoryGb := clickPipe.Scaling.GetMemoryGb()

		// Create scaling model with proper null handling
		var replicasValue types.Int64
		var cpuValue types.Int64
		var memoryValue types.Float64

		if clickPipe.Scaling.Replicas != nil {
			replicasValue = types.Int64Value(*clickPipe.Scaling.Replicas)
		} else {
			replicasValue = types.Int64Null()
		}

		if cpuMillicores != nil {
			cpuValue = types.Int64Value(*cpuMillicores)
		} else {
			cpuValue = types.Int64Null()
		}

		if memoryGb != nil {
			memoryValue = types.Float64Value(*memoryGb)
		} else {
			memoryValue = types.Float64Null()
		}

		scalingModel := models.ClickPipeScalingModel{
			Replicas:             replicasValue,
			ReplicaCpuMillicores: cpuValue,
			ReplicaMemoryGb:      memoryValue,
		}

		state.Scaling = scalingModel.ObjectValue()
	}

	stateSourceModel := models.ClickPipeSourceModel{}
	if !state.Source.IsNull() {
		if diags := state.Source.As(ctx, &stateSourceModel, basetypes.ObjectAsOptions{}); diags.HasError() {
			return fmt.Errorf("error reading ClickPipe source: %v", diags)
		}
	}

	sourceModel := models.ClickPipeSourceModel{}
	if clickPipe.Source.Kafka != nil {
		stateKafkaModel := models.ClickPipeKafkaSourceModel{}
		if !stateSourceModel.Kafka.IsNull() {
			if diags := stateSourceModel.Kafka.As(ctx, &stateKafkaModel, basetypes.ObjectAsOptions{}); diags.HasError() {
				return fmt.Errorf("error reading ClickPipe Kafka source: %v", diags)
			}
		}

		var consumerGroup string
		if clickPipe.Source.Kafka.ConsumerGroup != nil {
			consumerGroup = *clickPipe.Source.Kafka.ConsumerGroup
		}

		kafkaModel := models.ClickPipeKafkaSourceModel{
			Type:           types.StringValue(clickPipe.Source.Kafka.Type),
			Format:         types.StringValue(clickPipe.Source.Kafka.Format),
			Brokers:        types.StringValue(clickPipe.Source.Kafka.Brokers),
			Topics:         types.StringValue(clickPipe.Source.Kafka.Topics),
			ConsumerGroup:  types.StringValue(consumerGroup),
			Authentication: types.StringValue(clickPipe.Source.Kafka.Authentication),
			CACertificate:  types.StringPointerValue(clickPipe.Source.Kafka.CACertificate),
			IAMRole:        types.StringPointerValue(clickPipe.Source.Kafka.IAMRole),
		}

		if !stateKafkaModel.Credentials.IsNull() {
			stateCredentialsModel := models.ClickPipeKafkaSourceCredentialsModel{}
			if diags := stateKafkaModel.Credentials.As(ctx, &stateCredentialsModel, basetypes.ObjectAsOptions{}); diags.HasError() {
				return fmt.Errorf("error reading ClickPipe Kafka source credentials: %v", diags)
			}
			kafkaModel.Credentials = stateCredentialsModel.ObjectValue()
		} else {
			kafkaModel.Credentials = types.ObjectNull(models.ClickPipeKafkaSourceCredentialsModel{}.ObjectType().AttrTypes)
		}

		if clickPipe.Source.Kafka.SchemaRegistry != nil {
			var stateSchemaRegistryModel models.ClickPipeKafkaSchemaRegistryModel
			if !stateKafkaModel.SchemaRegistry.IsNull() {
				if diags := stateKafkaModel.SchemaRegistry.As(ctx, &stateSchemaRegistryModel, basetypes.ObjectAsOptions{}); diags.HasError() {
					return fmt.Errorf("error reading ClickPipe Kafka source schema registry: %v", diags)
				}
			}

			schemaRegistryModel := models.ClickPipeKafkaSchemaRegistryModel{
				URL:            types.StringValue(clickPipe.Source.Kafka.SchemaRegistry.URL),
				Authentication: types.StringValue(clickPipe.Source.Kafka.SchemaRegistry.Authentication),
				Credentials:    stateSchemaRegistryModel.Credentials,
			}

			kafkaModel.SchemaRegistry = schemaRegistryModel.ObjectValue()
		} else {
			kafkaModel.SchemaRegistry = types.ObjectNull(models.ClickPipeKafkaSchemaRegistryModel{}.ObjectType().AttrTypes)
		}

		if clickPipe.Source.Kafka.Offset != nil {
			offsetModel := models.ClickPipeKafkaOffsetModel{
				Strategy:  types.StringValue(clickPipe.Source.Kafka.Offset.Strategy),
				Timestamp: types.StringPointerValue(clickPipe.Source.Kafka.Offset.Timestamp),
			}

			kafkaModel.Offset = offsetModel.ObjectValue()
		} else {
			kafkaModel.Offset = types.ObjectNull(models.ClickPipeKafkaOffsetModel{}.ObjectType().AttrTypes)
		}

		if clickPipe.Source.Kafka.ReversePrivateEndpointIDs != nil {
			reversePrivateEndpointIDs := make([]attr.Value, len(clickPipe.Source.Kafka.ReversePrivateEndpointIDs))
			for i, id := range clickPipe.Source.Kafka.ReversePrivateEndpointIDs {
				reversePrivateEndpointIDs[i] = types.StringValue(id)
			}
			kafkaModel.ReversePrivateEndpointIDs, _ = types.ListValue(types.StringType, reversePrivateEndpointIDs)
		} else {
			kafkaModel.ReversePrivateEndpointIDs = types.ListNull(types.StringType)
		}

		sourceModel.Kafka = kafkaModel.ObjectValue()
	} else {
		sourceModel.Kafka = types.ObjectNull(models.ClickPipeKafkaSourceModel{}.ObjectType().AttrTypes)
	}

	if clickPipe.Source.ObjectStorage != nil {
		stateObjectStorageModel := models.ClickPipeObjectStorageSourceModel{}

		if !stateSourceModel.ObjectStorage.IsNull() {
			if diags := stateSourceModel.ObjectStorage.As(ctx, &stateObjectStorageModel, basetypes.ObjectAsOptions{}); diags.HasError() {
				return fmt.Errorf("error reading ClickPipe object storage source: %v", diags)
			}
		}

		objectStorageModel := models.ClickPipeObjectStorageSourceModel{
			Type:         types.StringValue(clickPipe.Source.ObjectStorage.Type),
			Format:       types.StringValue(clickPipe.Source.ObjectStorage.Format),
			Delimiter:    types.StringPointerValue(clickPipe.Source.ObjectStorage.Delimiter),
			Compression:  types.StringPointerValue(clickPipe.Source.ObjectStorage.Compression),
			IsContinuous: types.BoolValue(clickPipe.Source.ObjectStorage.IsContinuous),
			IAMRole:      types.StringPointerValue(clickPipe.Source.ObjectStorage.IAMRole),
		}

		// Set storage-type-specific fields
		if clickPipe.Source.ObjectStorage.Type == api.ClickPipeObjectStorageAzureBlobType {
			// For Azure Blob Storage, preserve all fields from state as API doesn't return them
			objectStorageModel.Authentication = stateObjectStorageModel.Authentication
			objectStorageModel.ConnectionString = stateObjectStorageModel.ConnectionString
			objectStorageModel.Path = stateObjectStorageModel.Path
			objectStorageModel.AzureContainerName = stateObjectStorageModel.AzureContainerName
		} else {
			// For S3-compatible storage, use API response values
			objectStorageModel.Authentication = types.StringPointerValue(clickPipe.Source.ObjectStorage.Authentication)
			objectStorageModel.URL = types.StringValue(clickPipe.Source.ObjectStorage.URL)
		}

		if !stateObjectStorageModel.AccessKey.IsNull() {
			stateAccessKeyModel := models.ClickPipeSourceAccessKeyModel{}
			if diags := stateObjectStorageModel.AccessKey.As(ctx, &stateAccessKeyModel, basetypes.ObjectAsOptions{}); diags.HasError() {
				return fmt.Errorf("error reading ClickPipe object storage source access key: %v", diags)
			}

			objectStorageModel.AccessKey = stateAccessKeyModel.ObjectValue()
		} else {
			objectStorageModel.AccessKey = types.ObjectNull(models.ClickPipeSourceAccessKeyModel{}.ObjectType().AttrTypes)
		}

		sourceModel.ObjectStorage = objectStorageModel.ObjectValue()
	} else {
		sourceModel.ObjectStorage = types.ObjectNull(models.ClickPipeObjectStorageSourceModel{}.ObjectType().AttrTypes)
	}

	if clickPipe.Source.Kinesis != nil {
		stateKinesisModel := models.ClickPipeKinesisSourceModel{}
		if !stateSourceModel.Kinesis.IsNull() {
			if diags := stateSourceModel.Kinesis.As(ctx, &stateKinesisModel, basetypes.ObjectAsOptions{}); diags.HasError() {
				return fmt.Errorf("error reading ClickPipe Kinesis source: %v", diags)
			}
		}

		kinesisModel := models.ClickPipeKinesisSourceModel{
			Format:            types.StringValue(clickPipe.Source.Kinesis.Format),
			StreamName:        types.StringValue(clickPipe.Source.Kinesis.StreamName),
			Region:            types.StringValue(clickPipe.Source.Kinesis.Region),
			IteratorType:      types.StringValue(clickPipe.Source.Kinesis.IteratorType),
			UseEnhancedFanOut: types.BoolValue(clickPipe.Source.Kinesis.UseEnhancedFanOut),
			Authentication:    types.StringValue(clickPipe.Source.Kinesis.Authentication),
			IAMRole:           types.StringPointerValue(clickPipe.Source.Kinesis.IAMRole),
			Timestamp:         types.StringPointerValue(clickPipe.Source.Kinesis.Timestamp),
		}

		if !stateKinesisModel.AccessKey.IsNull() {
			stateAccessKeyModel := models.ClickPipeSourceAccessKeyModel{}
			if diags := stateKinesisModel.AccessKey.As(ctx, &stateAccessKeyModel, basetypes.ObjectAsOptions{}); diags.HasError() {
				return fmt.Errorf("error reading ClickPipe Kinesis source access key: %v", diags)
			}

			kinesisModel.AccessKey = stateAccessKeyModel.ObjectValue()
		} else {
			kinesisModel.AccessKey = types.ObjectNull(models.ClickPipeSourceAccessKeyModel{}.ObjectType().AttrTypes)
		}

		sourceModel.Kinesis = kinesisModel.ObjectValue()
	} else {
		sourceModel.Kinesis = types.ObjectNull(models.ClickPipeKinesisSourceModel{}.ObjectType().AttrTypes)
	}

	state.Source = sourceModel.ObjectValue()

	destinationModel := models.ClickPipeDestinationModel{
		Database:        types.StringValue(clickPipe.Destination.Database),
		Table:           types.StringValue(clickPipe.Destination.Table),
		ManagedTable:    types.BoolValue(clickPipe.Destination.ManagedTable),
		TableDefinition: types.Object{},
		Columns:         types.List{},
		Roles:           types.List{},
	}

	stateDestinationModel := models.ClickPipeDestinationModel{}

	if !state.Destination.IsNull() {
		if diags := state.Destination.As(ctx, &stateDestinationModel, basetypes.ObjectAsOptions{}); diags.HasError() {
			return fmt.Errorf("error reading ClickPipe destination: %v", diags)
		}
	}

	// Destination roles are not persisted on ClickPipes side. Used only during pipe creation.
	if !stateDestinationModel.Roles.IsNull() {
		destinationModel.Roles = stateDestinationModel.Roles
	} else {
		destinationModel.Roles = types.ListNull(types.StringType)
	}

	columnList := make([]attr.Value, len(clickPipe.Destination.Columns))
	for i, column := range clickPipe.Destination.Columns {
		columnList[i] = models.ClickPipeDestinationColumnModel{
			Name: types.StringValue(column.Name),
			Type: types.StringValue(column.Type),
		}.ObjectValue()
	}

	destinationModel.Columns, _ = types.ListValue(models.ClickPipeDestinationColumnModel{}.ObjectType(), columnList)

	if clickPipe.Destination.TableDefinition != nil {
		engineModel := models.ClickPipeDestinationTableEngineModel{
			Type: types.StringValue(clickPipe.Destination.TableDefinition.Engine.Type),
		}

		tableDefinitionModel := models.ClickPipeDestinationTableDefinitionModel{
			Engine:      engineModel.ObjectValue(),
			PartitionBy: types.StringPointerValue(clickPipe.Destination.TableDefinition.PartitionBy),
			PrimaryKey:  types.StringPointerValue(clickPipe.Destination.TableDefinition.PrimaryKey),
		}

		if len(clickPipe.Destination.TableDefinition.SortingKey) > 0 {
			sortingKeyList := make([]attr.Value, len(clickPipe.Destination.TableDefinition.SortingKey))
			for i, sortingKey := range clickPipe.Destination.TableDefinition.SortingKey {
				sortingKeyList[i] = types.StringValue(sortingKey)
			}
			tableDefinitionModel.SortingKey, _ = types.ListValue(types.StringType, sortingKeyList)
		} else {
			tableDefinitionModel.SortingKey = types.ListNull(types.StringType)
		}

		destinationModel.TableDefinition = tableDefinitionModel.ObjectValue()
	} else {
		destinationModel.TableDefinition = types.ObjectNull(models.ClickPipeDestinationTableDefinitionModel{}.ObjectType().AttrTypes)
	}

	state.Destination = destinationModel.ObjectValue()

	if clickPipe.FieldMappings == nil || len(clickPipe.FieldMappings) == 0 {
		state.FieldMappings = types.ListNull(models.ClickPipeFieldMappingModel{}.ObjectType())
	} else {
		fieldMappingList := make([]attr.Value, len(clickPipe.FieldMappings))
		for i, fieldMapping := range clickPipe.FieldMappings {
			fieldMappingList[i] = models.ClickPipeFieldMappingModel{
				SourceField:      types.StringValue(fieldMapping.SourceField),
				DestinationField: types.StringValue(fieldMapping.DestinationField),
			}.ObjectValue()
		}

		state.FieldMappings, _ = types.ListValue(models.ClickPipeFieldMappingModel{}.ObjectType(), fieldMappingList)
	}

	// Handle settings
	if clickPipe.Settings != nil && len(clickPipe.Settings) > 0 {
		settingsElements := make(map[string]attr.Value)
		for key, value := range clickPipe.Settings {
			settingsElements[key] = utils.ConvertJSONValueToTerraform(value)
		}
		settingsObj, _ := types.ObjectValue(
			map[string]attr.Type{},
			make(map[string]attr.Value),
		)

		// Create object type dynamically based on actual values
		attrTypes := make(map[string]attr.Type)
		for key := range settingsElements {
			attrTypes[key] = settingsElements[key].Type(ctx)
		}

		settingsObj, _ = types.ObjectValue(attrTypes, settingsElements)
		state.Settings = types.DynamicValue(settingsObj)
	} else {
		state.Settings = types.DynamicNull()
	}

	return nil
}

func (c *ClickPipeResource) Read(ctx context.Context, request resource.ReadRequest, response *resource.ReadResponse) {
	var state models.ClickPipeResourceModel
	diags := request.State.Get(ctx, &state)
	response.Diagnostics.Append(diags...)
	if response.Diagnostics.HasError() {
		return
	}

	if err := c.syncClickPipeState(ctx, &state); err != nil {
		response.Diagnostics.AddError(
			"Error Reading ClickPipe",
			"Could not read ClickPipe, unexpected error: "+err.Error(),
		)
		return
	}

	if state.ID.IsNull() {
		// ClickPipe does not exist, removed outside Terraform
		response.State.RemoveResource(ctx)
		return
	}

	diags = response.State.Set(ctx, state)
	response.Diagnostics.Append(diags...)
}

func (c *ClickPipeResource) Update(ctx context.Context, req resource.UpdateRequest, response *resource.UpdateResponse) {
	var plan, state models.ClickPipeResourceModel
	diags := req.Plan.Get(ctx, &plan)
	response.Diagnostics.Append(diags...)
	diags = req.State.Get(ctx, &state)
	response.Diagnostics.Append(diags...)

	if response.Diagnostics.HasError() {
		return
	}

	if state.State.ValueString() == api.ClickPipeCompletedState {
		response.Diagnostics.AddError(
			"Error Modifying ClickPipe",
			fmt.Sprintf("ClickPipe is in the %s state and cannot be modified", api.ClickPipeCompletedState),
		)

		return
	}

	var pipeChanged bool
	var clickPipeUpdate api.ClickPipeUpdate

	if !plan.Name.Equal(state.Name) {
		pipeChanged = true
		clickPipeUpdate.Name = plan.Name.ValueStringPointer()
	}

	if !plan.Source.Equal(state.Source) {
		source := c.extractSourceFromPlan(ctx, response.Diagnostics, plan, true)

		if source.Kafka != nil {
			pipeChanged = true
			clickPipeUpdate.Source = source
		} else if source.ObjectStorage != nil {
			pipeChanged = true
			clickPipeUpdate.Source = source
		} else {
			response.Diagnostics.AddError(
				"ClickPipe only supports Kafka source updates",
				"Only Kafka source updates are supported",
			)
		}
	}

	if !plan.Destination.Attributes()["columns"].Equal(state.Destination.Attributes()["columns"]) || !plan.FieldMappings.Equal(state.FieldMappings) {
		pipeChanged = true
		destinationModel := models.ClickPipeDestinationModel{}
		response.Diagnostics.Append(plan.Destination.As(ctx, &destinationModel, basetypes.ObjectAsOptions{})...)
		destinationColumnsModels := make([]models.ClickPipeDestinationColumnModel, len(destinationModel.Columns.Elements()))
		response.Diagnostics.Append(destinationModel.Columns.ElementsAs(ctx, &destinationColumnsModels, false)...)

		clickPipeUpdate.Destination = &api.ClickPipeDestinationUpdate{
			Columns: make([]api.ClickPipeDestinationColumn, len(destinationColumnsModels)),
		}

		for i, columnModel := range destinationColumnsModels {
			clickPipeUpdate.Destination.Columns[i] = api.ClickPipeDestinationColumn{
				Name: columnModel.Name.ValueString(),
				Type: columnModel.Type.ValueString(),
			}
		}

		fieldMappingsModels := make([]models.ClickPipeFieldMappingModel, len(plan.FieldMappings.Elements()))
		response.Diagnostics.Append(plan.FieldMappings.ElementsAs(ctx, &fieldMappingsModels, false)...)

		clickPipeUpdate.FieldMappings = make([]api.ClickPipeFieldMapping, len(fieldMappingsModels))
		for i, fieldMappingModel := range fieldMappingsModels {
			clickPipeUpdate.FieldMappings[i] = api.ClickPipeFieldMapping{
				SourceField:      fieldMappingModel.SourceField.ValueString(),
				DestinationField: fieldMappingModel.DestinationField.ValueString(),
			}
		}
	}

	// Handle settings separately using dedicated endpoint
	var settingsChanged bool
	var newSettingsMap map[string]any

	if !plan.Settings.Equal(state.Settings) {
		settingsChanged = true
		newSettingsMap = make(map[string]any)
		if !plan.Settings.IsNull() && !plan.Settings.IsUnknown() {
			underlyingValue := plan.Settings.UnderlyingValue()

			// Settings should be an object/map at the top level
			if objValue, ok := underlyingValue.(types.Object); ok {
				for key, value := range objValue.Attributes() {
					newSettingsMap[key] = utils.ConvertTerraformValueToJSON(value)
				}
			}
		}
	}

	// Update the main ClickPipe if non-settings fields changed
	if pipeChanged {
		if _, err := c.client.UpdateClickPipe(ctx, state.ServiceID.ValueString(), state.ID.ValueString(), clickPipeUpdate); err != nil {
			response.Diagnostics.AddError(
				"Error Updating ClickPipe",
				"Could not update ClickPipe, unexpected error: "+err.Error(),
			)
			return
		}
	}

	// Update settings separately if they changed
	if settingsChanged {
		if _, err := c.client.UpdateClickPipeSettings(ctx, state.ServiceID.ValueString(), state.ID.ValueString(), newSettingsMap); err != nil {
			response.Diagnostics.AddError(
				"Error Updating ClickPipe Settings",
				"Could not update ClickPipe settings, unexpected error: "+err.Error(),
			)
			return
		}
	}

	if !plan.State.Equal(state.State) {
		var command string

		switch plan.State.ValueString() {
		case api.ClickPipeRunningState:
			command = api.ClickPipeStateStart
		case api.ClickPipeStoppedState:
			command = api.ClickPipeStateStop
		}

		if _, err := c.client.ChangeClickPipeState(ctx, state.ServiceID.ValueString(), state.ID.ValueString(), command); err != nil {
			response.Diagnostics.AddError(
				"Error Changing ClickPipe State",
				"Could not change ClickPipe state, unexpected error: "+err.Error(),
			)
			return
		}
	}

	if !plan.Scaling.Equal(state.Scaling) {
		scalingModel := models.ClickPipeScalingModel{}
		response.Diagnostics.Append(plan.Scaling.As(ctx, &scalingModel, basetypes.ObjectAsOptions{})...)

		scalingRequest := api.ClickPipeScalingRequest{}

		// Only include fields that are explicitly set (not null/unknown)
		if !scalingModel.Replicas.IsNull() && !scalingModel.Replicas.IsUnknown() {
			scalingRequest.Replicas = scalingModel.Replicas.ValueInt64Pointer()
		}
		if !scalingModel.ReplicaCpuMillicores.IsNull() && !scalingModel.ReplicaCpuMillicores.IsUnknown() {
			scalingRequest.ReplicaCpuMillicores = scalingModel.ReplicaCpuMillicores.ValueInt64Pointer()
		}
		if !scalingModel.ReplicaMemoryGb.IsNull() && !scalingModel.ReplicaMemoryGb.IsUnknown() {
			scalingRequest.ReplicaMemoryGb = scalingModel.ReplicaMemoryGb.ValueFloat64Pointer()
		}

		if _, err := c.client.ScalingClickPipe(ctx, state.ServiceID.ValueString(), state.ID.ValueString(), scalingRequest); err != nil {
			response.Diagnostics.AddError(
				"Error Scaling ClickPipe",
				"Could not scale ClickPipe, unexpected error: "+err.Error(),
			)
			return
		}
	}

	if _, err := c.client.WaitForClickPipeState(ctx, state.ServiceID.ValueString(), state.ID.ValueString(), func(state string) bool {
		return state == plan.State.ValueString()
	}, clickPipeStateChangeMaxWaitSeconds); err != nil {
		response.Diagnostics.AddWarning(
			"ClickPipe didn't reach the desired state",
			err.Error(),
		)
	}

	if err := c.syncClickPipeState(ctx, &plan); err != nil {
		response.Diagnostics.AddError(
			"Error Reading ClickPipe",
			"Could not read ClickPipe, unexpected error: "+err.Error(),
		)
		return
	}

	diags = response.State.Set(ctx, plan)
	response.Diagnostics.Append(diags...)
}

func (c *ClickPipeResource) Delete(ctx context.Context, request resource.DeleteRequest, response *resource.DeleteResponse) {
	var state models.ClickPipeResourceModel
	diags := request.State.Get(ctx, &state)
	response.Diagnostics.Append(diags...)
	if response.Diagnostics.HasError() {
		return
	}

	if err := c.client.DeleteClickPipe(ctx, state.ServiceID.ValueString(), state.ID.ValueString()); err != nil {
		response.Diagnostics.AddError(
			"Error Deleting ClickPipe",
			"Could not delete ClickPipe, unexpected error: "+err.Error(),
		)
	}
}

// ImportState imports a ClickPipe reverse private endpoint into the state.
// We don't have access to configuration/plan, so service id is required
// to be provided as a part of the import id.
func (r *ClickPipeResource) ImportState(ctx context.Context, req resource.ImportStateRequest, resp *resource.ImportStateResponse) {
	idParts := strings.Split(req.ID, ":")

	if len(idParts) != 2 {
		resp.Diagnostics.AddError(
			"Invalid Import ID",
			fmt.Sprintf("Expected import identifier with format: service_id:id. Got: %q", req.ID),
		)
		return
	}

	id := idParts[0]
	endpointID := idParts[1]

	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("service_id"), id)...)
	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("id"), endpointID)...)

	resp.Diagnostics.AddWarning(
		"Credentials state diverge",
		"Importing a ClickPipe will not persist credentials into your state.\n"+
			"Sensitive values are only stored in your state and provider is not able to import them.\n"+
			"Run a `terraform apply` to ensure sensitive values state is up to date with a ClickPipe.\n"+
			"Important: your configuration (in *.tf files) has to provide valid credentials.",
	)
}
