//go:build alpha

package resource

import (
	"context"
	"fmt"
	"strings"

	"github.com/hashicorp/terraform-plugin-framework-validators/int64validator"
	"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator"
	"github.com/hashicorp/terraform-plugin-framework/attr"
	"github.com/hashicorp/terraform-plugin-framework/diag"
	"github.com/hashicorp/terraform-plugin-framework/path"
	"github.com/hashicorp/terraform-plugin-framework/resource"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/booldefault"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/boolplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/int64default"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/listplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/objectplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringdefault"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/schema/validator"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-framework/types/basetypes"

	"github.com/ClickHouse/terraform-provider-clickhouse/pkg/internal/api"
	"github.com/ClickHouse/terraform-provider-clickhouse/pkg/resource/models"
)

var (
	_ resource.Resource               = &ClickPipeResource{}
	_ resource.ResourceWithModifyPlan = &ClickPipeResource{}
	_ resource.ResourceWithConfigure  = &ClickPipeResource{}
)

const clickPipeResourceDescription = `
This experimental resource allows you to create and manage ClickPipes data ingestion in ClickHouse Cloud.

Feature needs to be enabled on your account. Please contact ClickHouse Cloud support for more information. 

**Resource is early access and may change in future releases. Feature coverage might not fully cover all ClickPipe capabilities.**

Known limitations:
- ClickPipe is immutable. It means, any change to the ClickPipe will require a new resource to be created in-place. This does not apply to scaling and state changes.
- ClickPipe does not support table updates for managed tables. If you need to update the table schema, you will have to do that externally.
- Provider lacks validation logic. It means, the provider will not validate the ClickPipe configuration against the ClickHouse Cloud API. Any invalid configuration will be rejected by the API.
`

const (
	clickPipeStateChangeMaxWaitSeconds = 60 * 2
)

type ClickPipeResource struct {
	client api.Client
}

func NewClickPipeResource() resource.Resource {
	return &ClickPipeResource{}
}

func (c *ClickPipeResource) Configure(_ context.Context, request resource.ConfigureRequest, _ *resource.ConfigureResponse) {
	if request.ProviderData == nil {
		return
	}

	c.client = request.ProviderData.(api.Client)
}

func (c *ClickPipeResource) Metadata(_ context.Context, request resource.MetadataRequest, response *resource.MetadataResponse) {
	response.TypeName = request.ProviderTypeName + "_clickpipe"
}

func (c *ClickPipeResource) Schema(_ context.Context, _ resource.SchemaRequest, response *resource.SchemaResponse) {
	wrapStringsWithBackticksAndJoinCommaSeparated := func(s []string) string {
		wrapped := make([]string, len(s))
		for i, v := range s {
			wrapped[i] = "`" + v + "`"
		}
		return strings.Join(wrapped, ", ")
	}

	response.Schema = schema.Schema{
		MarkdownDescription: clickPipeResourceDescription,
		Attributes: map[string]schema.Attribute{
			"id": schema.StringAttribute{
				Description: "The ID of the ClickPipe. Generated by the ClickHouse Cloud.",
				Computed:    true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.UseStateForUnknown(),
				},
			},
			"service_id": schema.StringAttribute{
				Description: "The ID of the service to which the ClickPipe belongs.",
				Required:    true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.RequiresReplace(),
				},
			},
			"name": schema.StringAttribute{
				Description: "The name of the ClickPipe.",
				Required:    true,
			},
			"description": schema.StringAttribute{
				Description: "The description of the ClickPipe.",
				Optional:    true,
			},
			"scaling": schema.SingleNestedAttribute{
				Attributes: map[string]schema.Attribute{
					"replicas": schema.Int64Attribute{
						Description: "The number of desired replicas for the ClickPipe. Default is 1. The maximum value is 10.",
						Optional:    true,
						Computed:    true,
						Default:     int64default.StaticInt64(1),
						Validators: []validator.Int64{
							int64validator.Between(1, 10),
						},
					},
				},
				Optional: true,
			},
			"state": schema.StringAttribute{
				MarkdownDescription: "The desired state of the ClickPipe. (`Running`, `Stopped`). Default is `Running`.",
				Optional:            true,
				Default:             stringdefault.StaticString(api.ClickPipeRunningState),
				Computed:            true,
				Validators: []validator.String{
					stringvalidator.OneOf(api.ClickPipeRunningState, api.ClickPipeStoppedState),
				},
			},
			"source": schema.SingleNestedAttribute{
				Description: "The data source for the ClickPipe. At least one source configuration must be provided.",
				Attributes: map[string]schema.Attribute{
					"kafka": schema.SingleNestedAttribute{
						MarkdownDescription: "The Kafka source configuration for the ClickPipe.",
						Optional:            true,
						Attributes: map[string]schema.Attribute{
							"type": schema.StringAttribute{
								MarkdownDescription: fmt.Sprintf(
									"The type of the Kafka source. (%s). Default is `%s`.",
									wrapStringsWithBackticksAndJoinCommaSeparated(api.ClickPipeKafkaSourceTypes),
									api.ClickPipeKafkaSourceType,
								),
								Computed: true,
								Optional: true,
								Default:  stringdefault.StaticString(api.ClickPipeKafkaSourceType),
								Validators: []validator.String{
									stringvalidator.OneOf(api.ClickPipeKafkaSourceTypes...),
								},
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
							"format": schema.StringAttribute{
								MarkdownDescription: fmt.Sprintf(
									"The format of the Kafka source. (%s)",
									wrapStringsWithBackticksAndJoinCommaSeparated(api.ClickPipeKafkaFormats),
								),
								Required: true,
								Validators: []validator.String{
									stringvalidator.OneOf(api.ClickPipeKafkaFormats...),
								},
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplace(),
								},
							},
							"brokers": schema.StringAttribute{
								Description: "The list of Kafka bootstrap brokers. (comma separated)",
								Required:    true,
							},
							"topics": schema.StringAttribute{
								Description: "The list of Kafka topics. (comma separated)",
								Required:    true,
							},
							"consumer_group": schema.StringAttribute{
								MarkdownDescription: "Consumer group of the Kafka source. If not provided `clickpipes-<ID>` will be used.",
								Computed:            true,
								Optional:            true,
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.UseStateForUnknown(),
								},
							},
							"offset": schema.SingleNestedAttribute{
								MarkdownDescription: "The Kafka offset.",
								Optional:            true,
								Attributes: map[string]schema.Attribute{
									"strategy": schema.StringAttribute{
										MarkdownDescription: fmt.Sprintf(
											"The offset strategy for the Kafka source. (%s)",
											wrapStringsWithBackticksAndJoinCommaSeparated(api.ClickPipeKafkaOffsetStrategies),
										),
										Required: true,
										Validators: []validator.String{
											stringvalidator.OneOf(api.ClickPipeKafkaOffsetStrategies...),
										},
									},
									"timestamp": schema.StringAttribute{
										MarkdownDescription: fmt.Sprintf(
											"The timestamp for the Kafka offset. Use with `%s` offset strategy. (format `2021-01-01T00:00`)",
											api.ClickPipeKafkaOffsetFromTimestampStrategy,
										),
										Optional: true,
									},
								},
							},
							"schema_registry": schema.SingleNestedAttribute{
								MarkdownDescription: "The schema registry for the Kafka source.",
								Optional:            true,
								Attributes: map[string]schema.Attribute{
									"url": schema.StringAttribute{
										Description: "The URL of the schema registry.",
										Required:    true,
									},
									"authentication": schema.StringAttribute{
										Description: "The authentication method for the Schema Registry. Only supported is `PLAIN`.",
										Required:    true,
										Validators: []validator.String{
											stringvalidator.OneOf("PLAIN"),
										},
									},
									"credentials": schema.SingleNestedAttribute{
										MarkdownDescription: "The credentials for the Schema Registry.",
										Required:            true,
										Attributes: map[string]schema.Attribute{
											"username": schema.StringAttribute{
												Description: "The username for the Schema Registry.",
												Required:    true,
												Sensitive:   true,
											},
											"password": schema.StringAttribute{
												Description: "The password for the Schema Registry.",
												Required:    true,
												Sensitive:   true,
											},
										},
									},
								},
							},
							"authentication": schema.StringAttribute{
								MarkdownDescription: fmt.Sprintf(
									"The authentication method for the Kafka source. (%s). Default is `%s`.",
									wrapStringsWithBackticksAndJoinCommaSeparated(api.ClickPipeKafkaAuthenticationMethods),
									api.ClickPipeKafkaAuthenticationPlain,
								),
								Computed: true,
								Optional: true,
								Default:  stringdefault.StaticString("PLAIN"),
								Validators: []validator.String{
									stringvalidator.OneOf(api.ClickPipeKafkaAuthenticationMethods...),
								},
							},
							"credentials": schema.SingleNestedAttribute{
								MarkdownDescription: "The credentials for the Kafka source.",
								Attributes: map[string]schema.Attribute{
									"username": schema.StringAttribute{
										Description: "The username for the Kafka source.",
										Optional:    true,
										Sensitive:   true,
									},
									"password": schema.StringAttribute{
										Description: "The password for the Kafka source.",
										Optional:    true,
										Sensitive:   true,
									},
									"access_key_id": schema.StringAttribute{
										Description: "The access key ID for the Kafka source. Use with `IAM_USER` authentication.",
										Optional:    true,
										Sensitive:   true,
									},
									"secret_key": schema.StringAttribute{
										Description: "The secret key for the Kafka source. Use with `IAM_USER` authentication.",
										Optional:    true,
										Sensitive:   true,
									},
									"connection_string": schema.StringAttribute{
										Description: "The connection string for the Kafka source. Use with `azureeventhub` Kafka source type. Use with `PLAIN` authentication.",
										Optional:    true,
										Sensitive:   true,
									},
								},
								Optional: true,
							},
							"iam_role": schema.StringAttribute{
								MarkdownDescription: "The IAM role for the Kafka source. Use with `IAM_ROLE` authentication. It can be used with AWS ClickHouse service only. Read more in [ClickPipes documentation page](https://clickhouse.com/docs/en/integrations/clickpipes/kafka#iam)",
								Optional:            true,
							},
							"ca_certificate": schema.StringAttribute{
								MarkdownDescription: "PEM encoded CA certificates to validate the broker's certificate.",
								Optional:            true,
							},
						},
					},
					"object_storage": schema.SingleNestedAttribute{
						MarkdownDescription: "The Kafka source configuration for the ClickPipe.",
						Optional:            true,
						Attributes: map[string]schema.Attribute{
							"type": schema.StringAttribute{
								MarkdownDescription: fmt.Sprintf(
									"The type of the S3-compatbile source (%s). Default is `%s`.",
									wrapStringsWithBackticksAndJoinCommaSeparated(api.ClickPipeObjectStorageTypes),
									api.ClickPipeObjectStorageS3Type,
								),
								Computed: true,
								Optional: true,
								Default:  stringdefault.StaticString(api.ClickPipeObjectStorageS3Type),
								Validators: []validator.String{
									stringvalidator.OneOf(api.ClickPipeObjectStorageTypes...),
								},
							},
							"format": schema.StringAttribute{
								MarkdownDescription: fmt.Sprintf(
									"The format of the S3 objects. (%s)",
									wrapStringsWithBackticksAndJoinCommaSeparated(api.ClickPipeObjectStorageFormats),
								),
								Required: true,
								Validators: []validator.String{
									stringvalidator.OneOf(api.ClickPipeObjectStorageFormats...),
								},
							},
							"url": schema.StringAttribute{
								MarkdownDescription: "The URL of the S3 bucket. Provide a path to the file(s) you want to ingest. You can specify multiple files using bash-like wildcards. For more information, see the documentation on using wildcards in path: https://clickhouse.com/docs/en/integrations/clickpipes/object-storage#limitations",
								Required:            true,
							},
							"delimiter": schema.StringAttribute{
								MarkdownDescription: "The delimiter for the S3 source. Default is `,`.",
								Optional:            true,
							},
							"compression": schema.StringAttribute{
								MarkdownDescription: fmt.Sprintf(
									"Compression algorithm used for the files.. (%s)",
									wrapStringsWithBackticksAndJoinCommaSeparated(api.ClickPipeObjectStorageCompressions),
								),
								Optional: true,
								Validators: []validator.String{
									stringvalidator.OneOf(api.ClickPipeObjectStorageCompressions...),
								},
							},
							"is_continuous": schema.BoolAttribute{
								MarkdownDescription: "If set to true, the pipe will continuously read new files from the source. If set to false, the pipe will read the files only once. New files have to be uploaded lexically order.",
								Optional:            true,
								Computed:            true,
								Default:             booldefault.StaticBool(false),
							},
							"authentication": schema.StringAttribute{
								MarkdownDescription: fmt.Sprintf(
									"Authentication method. If not provided, no authentication is used. It can be used to access public buckets.. (%s).",
									wrapStringsWithBackticksAndJoinCommaSeparated(api.ClickPipeObjectStorageAuthenticationMethods),
								),
								Optional: true,
								Validators: []validator.String{
									stringvalidator.OneOf(api.ClickPipeObjectStorageAuthenticationMethods...),
								},
							},
							"access_key": schema.SingleNestedAttribute{
								MarkdownDescription: "Access key",
								Optional:            true,
								Attributes: map[string]schema.Attribute{
									"access_key_id": schema.StringAttribute{
										Description: "The access key ID for the S3 source. Use with `IAM_USER` authentication.",
										Optional:    true,
										Sensitive:   true,
									},
									"secret_key": schema.StringAttribute{
										Description: "The secret key for the S3 source. Use with `IAM_USER` authentication.",
										Optional:    true,
										Sensitive:   true,
									},
								},
							},
							"iam_role": schema.StringAttribute{
								MarkdownDescription: "The IAM role for the S3 source. Use with `IAM_ROLE` authentication. It can be used with AWS ClickHouse service only. Read more in [ClickPipes documentation page](https://clickhouse.com/docs/en/integrations/clickpipes/object-storage#authentication)",
								Optional:            true,
							},
						},
						PlanModifiers: []planmodifier.Object{
							objectplanmodifier.RequiresReplace(),
						},
					},
				},
				Required: true,
			},
			"destination": schema.SingleNestedAttribute{
				Description: "The destination for the ClickPipe.",
				Attributes: map[string]schema.Attribute{
					"database": schema.StringAttribute{
						MarkdownDescription: "The name of the ClickHouse database. Default is `default`.",
						Default:             stringdefault.StaticString("default"),
						Computed:            true,
						Optional:            true,
						PlanModifiers: []planmodifier.String{
							stringplanmodifier.RequiresReplace(),
						},
					},
					"table": schema.StringAttribute{
						Description: "The name of the ClickHouse table.",
						Required:    true,
						PlanModifiers: []planmodifier.String{
							stringplanmodifier.RequiresReplace(),
						},
					},
					"managed_table": schema.BoolAttribute{
						MarkdownDescription: "Whether the table is managed by ClickHouse Cloud. If `false`, the table must exist in the database. Default is `true`.",
						Default:             booldefault.StaticBool(true),
						Computed:            true,
						Optional:            true,
						PlanModifiers: []planmodifier.Bool{
							boolplanmodifier.RequiresReplace(),
						},
					},
					"table_definition": schema.SingleNestedAttribute{
						MarkdownDescription: "Definition of the destination table. Required for ClickPipes managed tables.",
						Optional:            true,
						Attributes: map[string]schema.Attribute{
							"engine": schema.SingleNestedAttribute{
								MarkdownDescription: "The engine of the ClickHouse table.",
								Required:            true,
								Attributes: map[string]schema.Attribute{
									"type": schema.StringAttribute{
										MarkdownDescription: "The type of the engine. Only `MergeTree` is supported.",
										Required:            true,
										Validators: []validator.String{
											stringvalidator.OneOf("MergeTree"),
										},
									},
								},
							},
							"sorting_key": schema.ListAttribute{
								MarkdownDescription: "The list of columns for the sorting key.",
								Optional:            true,
								ElementType:         types.StringType,
							},
							"partition_by": schema.StringAttribute{
								MarkdownDescription: "The column to partition the table by.",
								Optional:            true,
							},
							"primary_key": schema.StringAttribute{
								MarkdownDescription: "The primary key of the table.",
								Optional:            true,
							},
						},
						PlanModifiers: []planmodifier.Object{
							objectplanmodifier.RequiresReplace(),
						},
					},
					"columns": schema.ListNestedAttribute{
						Description: "The list of columns for the ClickHouse table.",
						NestedObject: schema.NestedAttributeObject{
							Attributes: map[string]schema.Attribute{
								"name": schema.StringAttribute{
									Description: "The name of the column.",
									Required:    true,
								},
								"type": schema.StringAttribute{
									Description: "The type of the column.",
									Required:    true,
								},
							},
						},
						Required: true,
					},
					"roles": schema.ListAttribute{
						MarkdownDescription: "ClickPipe will create a ClickHouse user with these roles. Add your custom roles here if required.",
						ElementType:         types.StringType,
						Optional:            true,
						PlanModifiers: []planmodifier.List{
							listplanmodifier.RequiresReplace(),
						},
					},
				},
				Required: true,
			},
			"field_mappings": schema.ListNestedAttribute{
				Description: "Field mapping between source and destination table.",
				Optional:    true,
				NestedObject: schema.NestedAttributeObject{
					Attributes: map[string]schema.Attribute{
						"source_field": schema.StringAttribute{
							Description: "The name of the source field.",
							Required:    true,
						},
						"destination_field": schema.StringAttribute{
							Description: "The name of the column in destination table.",
							Required:    true,
						},
					},
				},
			},
		},
	}
}

func (c *ClickPipeResource) ModifyPlan(ctx context.Context, request resource.ModifyPlanRequest, response *resource.ModifyPlanResponse) {
	if request.Plan.Raw.IsNull() {
		// If the entire plan is null, the resource is planned for destruction.
		return
	}

	var plan, state, config models.ClickPipeResourceModel
	diags := request.Plan.Get(ctx, &plan)
	response.Diagnostics.Append(diags...)
	if !request.State.Raw.IsNull() {
		diags = request.State.Get(ctx, &state)
		response.Diagnostics.Append(diags...)
	}
	if response.Diagnostics.HasError() {
		return
	}

	if !request.Config.Raw.IsNull() {
		diags = request.Config.Get(ctx, &config)
		response.Diagnostics.Append(diags...)
	}
	if response.Diagnostics.HasError() {
		return
	}

	if !request.State.Raw.IsNull() {
		if !plan.ServiceID.IsNull() && plan.ServiceID != state.ServiceID {
			response.Diagnostics.AddAttributeError(
				path.Root("service_id"),
				"Invalid Update",
				"ClickPipe cannot be moved between services. Please delete and recreate the ClickPipe.",
			)
		}
	}
}

func (c *ClickPipeResource) Create(ctx context.Context, request resource.CreateRequest, response *resource.CreateResponse) {
	var plan models.ClickPipeResourceModel
	diags := request.Plan.Get(ctx, &plan)
	response.Diagnostics.Append(diags...)
	if response.Diagnostics.HasError() {
		return
	}

	serviceID := plan.ServiceID.ValueString()

	clickPipe := api.ClickPipe{
		Name:        plan.Name.ValueString(),
		Description: plan.Description.ValueStringPointer(),
	}

	if source := c.extractSourceFromPlan(ctx, response.Diagnostics, plan, false); source != nil {
		clickPipe.Source = *source
	} else {
		return
	}

	destinationModel := models.ClickPipeDestinationModel{}
	response.Diagnostics.Append(plan.Destination.As(ctx, &destinationModel, basetypes.ObjectAsOptions{})...)
	destinationColumnsModels := make([]models.ClickPipeDestinationColumnModel, len(destinationModel.Columns.Elements()))
	response.Diagnostics.Append(destinationModel.Columns.ElementsAs(ctx, &destinationColumnsModels, false)...)

	clickPipe.Destination = api.ClickPipeDestination{
		Database:     destinationModel.Database.ValueString(),
		Table:        destinationModel.Table.ValueString(),
		ManagedTable: destinationModel.ManagedTable.ValueBool(),
		Columns:      make([]api.ClickPipeDestinationColumn, len(destinationColumnsModels)),
	}

	if destinationModel.ManagedTable.ValueBool() {
		if destinationModel.TableDefinition.IsNull() {
			response.Diagnostics.AddError(
				"Error Creating ClickPipe",
				"Managed table requires table definition",
			)
			return
		}

		tableDefinitionModel := models.ClickPipeDestinationTableDefinitionModel{}
		response.Diagnostics.Append(destinationModel.TableDefinition.As(ctx, &tableDefinitionModel, basetypes.ObjectAsOptions{})...)

		sortingKey := make([]string, len(tableDefinitionModel.SortingKey.Elements()))

		for i, sortingKeyModel := range tableDefinitionModel.SortingKey.Elements() {
			sortingKey[i] = sortingKeyModel.String()
		}

		tableEngineModel := models.ClickPipeDestinationTableEngineModel{}
		response.Diagnostics.Append(tableDefinitionModel.Engine.As(ctx, &tableEngineModel, basetypes.ObjectAsOptions{})...)

		clickPipe.Destination.TableDefinition = &api.ClickPipeDestinationTableDefinition{
			Engine:      api.ClickPipeDestinationTableEngine{Type: tableEngineModel.Type.ValueString()},
			PartitionBy: tableDefinitionModel.PartitionBy.ValueStringPointer(),
			PrimaryKey:  tableDefinitionModel.PrimaryKey.ValueStringPointer(),
			SortingKey:  sortingKey,
		}
	}

	for i, columnModel := range destinationColumnsModels {
		clickPipe.Destination.Columns[i] = api.ClickPipeDestinationColumn{
			Name: columnModel.Name.ValueString(),
			Type: columnModel.Type.ValueString(),
		}
	}

	fieldMappingsModels := make([]models.ClickPipeFieldMappingModel, len(plan.FieldMappings.Elements()))
	response.Diagnostics.Append(plan.FieldMappings.ElementsAs(ctx, &fieldMappingsModels, false)...)
	clickPipe.FieldMappings = make([]api.ClickPipeFieldMapping, len(fieldMappingsModels))
	for i, fieldMappingModel := range fieldMappingsModels {
		clickPipe.FieldMappings[i] = api.ClickPipeFieldMapping{
			SourceField:      fieldMappingModel.SourceField.ValueString(),
			DestinationField: fieldMappingModel.DestinationField.ValueString(),
		}
	}

	createdClickPipe, err := c.client.CreateClickPipe(ctx, serviceID, clickPipe)
	if err != nil {
		response.Diagnostics.AddError(
			"Error Creating ClickPipe",
			"Could not create ClickPipe, unexpected error: "+err.Error(),
		)
		return
	}

	if !plan.Scaling.IsNull() {
		replicasModel := models.ClickPipeScalingModel{}
		response.Diagnostics.Append(plan.Scaling.As(ctx, &replicasModel, basetypes.ObjectAsOptions{})...)

		var desiredReplicas *int64
		if !replicasModel.Replicas.IsNull() && createdClickPipe.Scaling.Replicas != nil && *createdClickPipe.Scaling.Replicas != replicasModel.Replicas.ValueInt64() {
			desiredReplicas = replicasModel.Replicas.ValueInt64Pointer()
		}

		if desiredReplicas != nil {
			scalingRequest := api.ClickPipeScaling{
				Replicas: desiredReplicas,
			}

			if createdClickPipe, err = c.client.ScalingClickPipe(ctx, serviceID, createdClickPipe.ID, scalingRequest); err != nil {
				response.Diagnostics.AddError(
					"Error Scaling ClickPipe",
					"Could not scale ClickPipe, unexpected error: "+err.Error(),
				)
				return
			}
		}
	}

	if plan.State.ValueString() == api.ClickPipeStoppedState {
		if _, err := c.client.ChangeClickPipeState(ctx, serviceID, createdClickPipe.ID, api.ClickPipeStoppedState); err != nil {
			response.Diagnostics.AddError(
				"Error Stopping ClickPipe",
				"Could not stop ClickPipe, unexpected error: "+err.Error(),
			)
			return
		}
	}

	if _, err := c.client.WaitForClickPipeState(ctx, serviceID, createdClickPipe.ID, func(state string) bool {
		return state == plan.State.ValueString() // we expect the state to be the same as planned: "Running" or "Stopped"
	}, clickPipeStateChangeMaxWaitSeconds); err != nil {
		response.Diagnostics.AddWarning(
			"ClickPipe didn't reach the desired state",
			err.Error(),
		)
	}

	plan.ID = types.StringValue(createdClickPipe.ID)

	if err := c.syncClickPipeState(ctx, &plan); err != nil {
		response.Diagnostics.AddError(
			"Error reading ClickPipe",
			"Could not read ClickPipe, unexpected error: "+err.Error(),
		)
		return
	}

	diags = response.State.Set(ctx, plan)
	response.Diagnostics.Append(diags...)
}

func (c *ClickPipeResource) extractSourceFromPlan(ctx context.Context, diagnostics diag.Diagnostics, plan models.ClickPipeResourceModel, isUpdate bool) *api.ClickPipeSource {
	source := &api.ClickPipeSource{}

	sourceModel := models.ClickPipeSourceModel{}
	diagnostics.Append(plan.Source.As(ctx, &sourceModel, basetypes.ObjectAsOptions{})...)

	if !sourceModel.Kafka.IsNull() {
		kafkaModel := models.ClickPipeKafkaSourceModel{}
		diagnostics.Append(sourceModel.Kafka.As(ctx, &kafkaModel, basetypes.ObjectAsOptions{})...)

		var consumerGroup *string
		if !kafkaModel.ConsumerGroup.IsUnknown() {
			consumerGroup = kafkaModel.ConsumerGroup.ValueStringPointer()
		}

		source.Kafka = &api.ClickPipeKafkaSource{
			Brokers:        kafkaModel.Brokers.ValueString(),
			Topics:         kafkaModel.Topics.ValueString(),
			ConsumerGroup:  consumerGroup,
			Authentication: kafkaModel.Authentication.ValueString(),
			IAMRole:        kafkaModel.IAMRole.ValueStringPointer(),
			CACertificate:  kafkaModel.CACertificate.ValueStringPointer(),
		}

		if !isUpdate {
			source.Kafka.Type = kafkaModel.Type.ValueString()
			source.Kafka.Format = kafkaModel.Format.ValueString()
		}

		if kafkaModel.Authentication.ValueString() != api.ClickPipeAuthenticationIAMRole {
			if !kafkaModel.Credentials.IsNull() {
				credentialsModel := models.ClickPipeKafkaSourceCredentialsModel{}
				diagnostics.Append(kafkaModel.Credentials.As(ctx, &credentialsModel, basetypes.ObjectAsOptions{})...)

				var credentials *api.ClickPipeKafkaSourceCredentials

				if kafkaModel.Authentication.ValueString() != api.ClickPipeAuthenticationIAMRole {
					credentials = &api.ClickPipeKafkaSourceCredentials{}

					if !credentialsModel.Username.IsNull() && !credentialsModel.Password.IsNull() {
						credentials.ClickPipeSourceCredentials = &api.ClickPipeSourceCredentials{
							Username: credentialsModel.Username.ValueString(),
							Password: credentialsModel.Password.ValueString(),
						}
					} else if !credentialsModel.AccessKeyID.IsNull() && !credentialsModel.SecretKey.IsNull() {
						credentials.ClickPipeSourceAccessKey = &api.ClickPipeSourceAccessKey{
							AccessKeyID: credentialsModel.AccessKeyID.ValueString(),
							SecretKey:   credentialsModel.SecretKey.ValueString(),
						}
					} else if !credentialsModel.ConnectionString.IsNull() {
						credentials.ConnectionString = credentialsModel.ConnectionString.ValueStringPointer()
					} else {
						diagnostics.AddError(
							"Error Creating ClickPipe",
							"Kafka source requires credentials",
						)
						return nil
					}
				}

				source.Kafka.Credentials = credentials
			} else {
				diagnostics.AddError(
					"Error Creating ClickPipe",
					"Kafka source requires credentials",
				)
				return nil
			}
		}

		if !kafkaModel.SchemaRegistry.IsNull() {
			schemaRegistryModel := models.ClickPipeKafkaSchemaRegistryModel{}
			diagnostics.Append(kafkaModel.SchemaRegistry.As(ctx, &schemaRegistryModel, basetypes.ObjectAsOptions{})...)
			credentialsModel := models.ClickPipeSourceCredentialsModel{}
			diagnostics.Append(schemaRegistryModel.Credentials.As(ctx, &credentialsModel, basetypes.ObjectAsOptions{})...)

			source.Kafka.SchemaRegistry = &api.ClickPipeKafkaSchemaRegistry{
				URL:            schemaRegistryModel.URL.ValueString(),
				Authentication: schemaRegistryModel.Authentication.ValueString(),
				Credentials: &api.ClickPipeSourceCredentials{
					Username: credentialsModel.Username.ValueString(),
					Password: credentialsModel.Password.ValueString(),
				},
			}
		}

		if !kafkaModel.Offset.IsNull() {
			offsetModel := models.ClickPipeKafkaOffsetModel{}
			diagnostics.Append(kafkaModel.Offset.As(ctx, &offsetModel, basetypes.ObjectAsOptions{})...)

			var timestamp *string
			if !offsetModel.Timestamp.IsUnknown() {
				timestamp = offsetModel.Timestamp.ValueStringPointer()
			}

			source.Kafka.Offset = &api.ClickPipeKafkaOffset{
				Strategy:  offsetModel.Strategy.ValueString(),
				Timestamp: timestamp,
			}
		}
	} else if !sourceModel.ObjectStorage.IsNull() {
		objectStorageModel := models.ClickPipeObjectStorageSourceModel{}

		diagnostics.Append(sourceModel.ObjectStorage.As(ctx, &objectStorageModel, basetypes.ObjectAsOptions{})...)

		var accessKey *api.ClickPipeSourceAccessKey
		if !objectStorageModel.AccessKey.IsUnknown() && !objectStorageModel.AccessKey.IsNull() {
			accessKeyModel := models.ClickPipeSourceAccessKeyModel{}
			diagnostics.Append(objectStorageModel.AccessKey.As(ctx, &accessKeyModel, basetypes.ObjectAsOptions{})...)

			accessKey = &api.ClickPipeSourceAccessKey{
				AccessKeyID: accessKeyModel.AccessKeyID.ValueString(),
				SecretKey:   accessKeyModel.SecretKey.ValueString(),
			}
		}

		source.ObjectStorage = &api.ClickPipeObjectStorageSource{
			Type:           objectStorageModel.Type.ValueString(),
			Format:         objectStorageModel.Format.ValueString(),
			URL:            objectStorageModel.URL.ValueString(),
			Delimiter:      objectStorageModel.Delimiter.ValueStringPointer(),
			Compression:    objectStorageModel.Compression.ValueStringPointer(),
			IsContinuous:   objectStorageModel.IsContinuous.ValueBool(),
			Authentication: objectStorageModel.Authentication.ValueStringPointer(),
			AccessKey:      accessKey,
			IAMRole:        objectStorageModel.IAMRole.ValueStringPointer(),
		}
	} else {
		diagnostics.AddError(
			"Error Creating ClickPipe",
			"ClickPipe requires at least one source configuration",
		)
		return nil
	}

	return source
}

func (c *ClickPipeResource) syncClickPipeState(ctx context.Context, state *models.ClickPipeResourceModel) error {
	if state.ID.IsNull() {
		return fmt.Errorf("ClickPipe ID is required to sync state")
	}

	clickPipe, err := c.client.GetClickPipe(ctx, state.ServiceID.ValueString(), state.ID.ValueString())
	if api.IsNotFound(err) {
		// ClickPipe does not exist, deleted outside Terraform
		state.ID = types.StringNull()
		return nil
	} else if err != nil {
		return err
	}

	state.ID = types.StringValue(clickPipe.ID)
	state.Name = types.StringValue(clickPipe.Name)

	// ideally, we shouldn't receive an empty description from the API, but we should handle it just in case
	if clickPipe.Description != nil && *clickPipe.Description != "" {
		state.Description = types.StringPointerValue(clickPipe.Description)
	} else {
		state.Description = types.StringNull()
	}

	// In case ClickPipe status is not as expected,
	// we should return an error that clearly states the issue so the user can take action.
	if clickPipe.State != state.State.ValueString() {
		if clickPipe.State == api.ClickPipeFailedState {
			return fmt.Errorf("ClickPipe is in a failed state: %s. Review the ClickPipe logs in the ClickHouse Cloud Console", clickPipe.State)
		}

		if clickPipe.State == api.ClickPipeInternalErrorState {
			return fmt.Errorf("ClickPipe is in an internal error state. Contact ClickHouse Cloud support for assistance")
		}

		// this should never happen, but let's handle it just in case
		return fmt.Errorf("ClickPipe is in an unexpected state: %s", clickPipe.State)
	}

	state.State = types.StringValue(clickPipe.State)

	if clickPipe.Scaling != nil && clickPipe.Scaling.Replicas != nil {
		scalingModel := models.ClickPipeScalingModel{
			Replicas: types.Int64PointerValue(clickPipe.Scaling.Replicas),
		}

		state.Scaling = scalingModel.ObjectValue()
	} else {
		state.Scaling = types.ObjectNull(models.ClickPipeScalingModel{}.ObjectType().AttrTypes)
	}

	stateSourceModel := models.ClickPipeSourceModel{}
	if diags := state.Source.As(ctx, &stateSourceModel, basetypes.ObjectAsOptions{}); diags.HasError() {
		return fmt.Errorf("error reading ClickPipe source: %v", diags)
	}

	sourceModel := models.ClickPipeSourceModel{}
	if clickPipe.Source.Kafka != nil {
		stateKafkaModel := models.ClickPipeKafkaSourceModel{}
		if diags := stateSourceModel.Kafka.As(ctx, &stateKafkaModel, basetypes.ObjectAsOptions{}); diags.HasError() {
			return fmt.Errorf("error reading ClickPipe Kafka source: %v", diags)
		}

		var consumerGroup string
		if clickPipe.Source.Kafka.ConsumerGroup != nil {
			consumerGroup = *clickPipe.Source.Kafka.ConsumerGroup
		}

		kafkaModel := models.ClickPipeKafkaSourceModel{
			Type:           types.StringValue(clickPipe.Source.Kafka.Type),
			Format:         types.StringValue(clickPipe.Source.Kafka.Format),
			Brokers:        types.StringValue(clickPipe.Source.Kafka.Brokers),
			Topics:         types.StringValue(clickPipe.Source.Kafka.Topics),
			ConsumerGroup:  types.StringValue(consumerGroup),
			Authentication: types.StringValue(clickPipe.Source.Kafka.Authentication),
			CACertificate:  types.StringPointerValue(clickPipe.Source.Kafka.CACertificate),
			IAMRole:        types.StringPointerValue(clickPipe.Source.Kafka.IAMRole),
		}

		if !stateKafkaModel.Credentials.IsNull() {
			stateCredentialsModel := models.ClickPipeKafkaSourceCredentialsModel{}
			if diags := stateKafkaModel.Credentials.As(ctx, &stateCredentialsModel, basetypes.ObjectAsOptions{}); diags.HasError() {
				return fmt.Errorf("error reading ClickPipe Kafka source credentials: %v", diags)
			}
			kafkaModel.Credentials = stateCredentialsModel.ObjectValue()
		} else {
			kafkaModel.Credentials = types.ObjectNull(models.ClickPipeKafkaSourceCredentialsModel{}.ObjectType().AttrTypes)
		}

		if clickPipe.Source.Kafka.SchemaRegistry != nil {
			var stateSchemaRegistryModel models.ClickPipeKafkaSchemaRegistryModel
			if diags := stateKafkaModel.SchemaRegistry.As(ctx, &stateSchemaRegistryModel, basetypes.ObjectAsOptions{}); diags.HasError() {
				return fmt.Errorf("error reading ClickPipe Kafka source schema registry: %v", diags)
			}

			schemaRegistryModel := models.ClickPipeKafkaSchemaRegistryModel{
				URL:            types.StringValue(clickPipe.Source.Kafka.SchemaRegistry.URL),
				Authentication: types.StringValue(clickPipe.Source.Kafka.SchemaRegistry.Authentication),
				Credentials:    stateSchemaRegistryModel.Credentials,
			}

			kafkaModel.SchemaRegistry = schemaRegistryModel.ObjectValue()
		} else {
			kafkaModel.SchemaRegistry = types.ObjectNull(models.ClickPipeKafkaSchemaRegistryModel{}.ObjectType().AttrTypes)
		}

		if clickPipe.Source.Kafka.Offset != nil {
			offsetModel := models.ClickPipeKafkaOffsetModel{
				Strategy:  types.StringValue(clickPipe.Source.Kafka.Offset.Strategy),
				Timestamp: types.StringPointerValue(clickPipe.Source.Kafka.Offset.Timestamp),
			}

			kafkaModel.Offset = offsetModel.ObjectValue()
		} else {
			kafkaModel.Offset = types.ObjectNull(models.ClickPipeKafkaOffsetModel{}.ObjectType().AttrTypes)
		}

		sourceModel.Kafka = kafkaModel.ObjectValue()
	} else {
		sourceModel.Kafka = types.ObjectNull(models.ClickPipeKafkaSourceModel{}.ObjectType().AttrTypes)
	}

	if clickPipe.Source.ObjectStorage != nil {
		stateObjectStorageModel := models.ClickPipeObjectStorageSourceModel{}
		if diags := stateSourceModel.ObjectStorage.As(ctx, &stateObjectStorageModel, basetypes.ObjectAsOptions{}); diags.HasError() {
			return fmt.Errorf("error reading ClickPipe object storage source: %v", diags)
		}

		objectStorageModel := models.ClickPipeObjectStorageSourceModel{
			Type:           types.StringValue(clickPipe.Source.ObjectStorage.Type),
			Format:         types.StringValue(clickPipe.Source.ObjectStorage.Format),
			URL:            types.StringValue(clickPipe.Source.ObjectStorage.URL),
			Delimiter:      types.StringPointerValue(clickPipe.Source.ObjectStorage.Delimiter),
			Compression:    types.StringPointerValue(clickPipe.Source.ObjectStorage.Compression),
			IsContinuous:   types.BoolValue(clickPipe.Source.ObjectStorage.IsContinuous),
			Authentication: types.StringPointerValue(clickPipe.Source.ObjectStorage.Authentication),
			IAMRole:        types.StringPointerValue(clickPipe.Source.ObjectStorage.IAMRole),
		}

		if !stateObjectStorageModel.AccessKey.IsNull() {
			stateAccessKeyModel := models.ClickPipeSourceAccessKeyModel{}
			if diags := stateObjectStorageModel.AccessKey.As(ctx, &stateAccessKeyModel, basetypes.ObjectAsOptions{}); diags.HasError() {
				return fmt.Errorf("error reading ClickPipe object storage source access key: %v", diags)
			}

			objectStorageModel.AccessKey = stateAccessKeyModel.ObjectValue()
		} else {
			objectStorageModel.AccessKey = types.ObjectNull(models.ClickPipeSourceAccessKeyModel{}.ObjectType().AttrTypes)
		}

		sourceModel.ObjectStorage = objectStorageModel.ObjectValue()
	} else {
		sourceModel.ObjectStorage = types.ObjectNull(models.ClickPipeObjectStorageSourceModel{}.ObjectType().AttrTypes)
	}

	state.Source = sourceModel.ObjectValue()

	destinationModel := models.ClickPipeDestinationModel{
		Database:        types.StringValue(clickPipe.Destination.Database),
		Table:           types.StringValue(clickPipe.Destination.Table),
		ManagedTable:    types.BoolValue(clickPipe.Destination.ManagedTable),
		TableDefinition: types.Object{},
		Columns:         types.List{},
		Roles:           types.List{},
	}

	stateDestinationModel := models.ClickPipeDestinationModel{}
	if diags := state.Destination.As(ctx, &stateDestinationModel, basetypes.ObjectAsOptions{}); diags.HasError() {
		return fmt.Errorf("error reading ClickPipe destination: %v", diags)
	}

	// Destination roles are not persisted on ClickPipes side. Used only during pipe creation.
	destinationModel.Roles = stateDestinationModel.Roles

	columnList := make([]attr.Value, len(clickPipe.Destination.Columns))
	for i, column := range clickPipe.Destination.Columns {
		columnList[i] = models.ClickPipeDestinationColumnModel{
			Name: types.StringValue(column.Name),
			Type: types.StringValue(column.Type),
		}.ObjectValue()
	}

	destinationModel.Columns, _ = types.ListValue(models.ClickPipeDestinationColumnModel{}.ObjectType(), columnList)

	if clickPipe.Destination.TableDefinition != nil {
		engineModel := models.ClickPipeDestinationTableEngineModel{
			Type: types.StringValue(clickPipe.Destination.TableDefinition.Engine.Type),
		}

		tableDefinitionModel := models.ClickPipeDestinationTableDefinitionModel{
			Engine:      engineModel.ObjectValue(),
			PartitionBy: types.StringPointerValue(clickPipe.Destination.TableDefinition.PartitionBy),
			PrimaryKey:  types.StringPointerValue(clickPipe.Destination.TableDefinition.PrimaryKey),
		}

		if len(clickPipe.Destination.TableDefinition.SortingKey) > 0 {
			sortingKeyList := make([]attr.Value, len(clickPipe.Destination.TableDefinition.SortingKey))
			for i, sortingKey := range clickPipe.Destination.TableDefinition.SortingKey {
				sortingKeyList[i] = types.StringValue(sortingKey)
			}
			tableDefinitionModel.SortingKey, _ = types.ListValue(types.StringType, sortingKeyList)
		} else {
			tableDefinitionModel.SortingKey = types.ListNull(types.StringType)
		}

		destinationModel.TableDefinition = tableDefinitionModel.ObjectValue()
	} else {
		destinationModel.TableDefinition = types.ObjectNull(models.ClickPipeDestinationTableDefinitionModel{}.ObjectType().AttrTypes)
	}

	state.Destination = destinationModel.ObjectValue()

	if clickPipe.FieldMappings == nil || len(clickPipe.FieldMappings) == 0 {
		state.FieldMappings = types.ListNull(models.ClickPipeFieldMappingModel{}.ObjectType())
	} else {
		fieldMappingList := make([]attr.Value, len(clickPipe.FieldMappings))
		for i, fieldMapping := range clickPipe.FieldMappings {
			fieldMappingList[i] = models.ClickPipeFieldMappingModel{
				SourceField:      types.StringValue(fieldMapping.SourceField),
				DestinationField: types.StringValue(fieldMapping.DestinationField),
			}.ObjectValue()
		}

		state.FieldMappings, _ = types.ListValue(models.ClickPipeFieldMappingModel{}.ObjectType(), fieldMappingList)
	}

	return nil
}

func (c *ClickPipeResource) Read(ctx context.Context, request resource.ReadRequest, response *resource.ReadResponse) {
	var state models.ClickPipeResourceModel
	diags := request.State.Get(ctx, &state)
	response.Diagnostics.Append(diags...)
	if response.Diagnostics.HasError() {
		return
	}

	if err := c.syncClickPipeState(ctx, &state); err != nil {
		response.Diagnostics.AddError(
			"Error Reading ClickPipe",
			"Could not read ClickPipe, unexpected error: "+err.Error(),
		)
		return
	}

	if state.ID.IsNull() {
		// ClickPipe does not exist, removed outside Terraform
		response.State.RemoveResource(ctx)
		return
	}

	diags = response.State.Set(ctx, state)
	response.Diagnostics.Append(diags...)
}

func (c *ClickPipeResource) Update(ctx context.Context, req resource.UpdateRequest, response *resource.UpdateResponse) {
	var plan, state models.ClickPipeResourceModel
	diags := req.Plan.Get(ctx, &plan)
	response.Diagnostics.Append(diags...)
	diags = req.State.Get(ctx, &state)
	response.Diagnostics.Append(diags...)

	if response.Diagnostics.HasError() {
		return
	}

	if !plan.State.Equal(state.State) {
		var command string

		switch plan.State.ValueString() {
		case api.ClickPipeRunningState:
			command = api.ClickPipeStateStart
		case api.ClickPipeStoppedState:
			command = api.ClickPipeStateStop
		}

		if _, err := c.client.ChangeClickPipeState(ctx, state.ServiceID.ValueString(), state.ID.ValueString(), command); err != nil {
			response.Diagnostics.AddError(
				"Error Changing ClickPipe State",
				"Could not change ClickPipe state, unexpected error: "+err.Error(),
			)
			return
		}
	}

	if !plan.Scaling.Equal(state.Scaling) {
		replicasModel := models.ClickPipeScalingModel{}
		response.Diagnostics.Append(plan.Scaling.As(ctx, &replicasModel, basetypes.ObjectAsOptions{})...)

		scalingRequest := api.ClickPipeScaling{
			Replicas: replicasModel.Replicas.ValueInt64Pointer(),
		}

		if _, err := c.client.ScalingClickPipe(ctx, state.ServiceID.ValueString(), state.ID.ValueString(), scalingRequest); err != nil {
			response.Diagnostics.AddError(
				"Error Scaling ClickPipe",
				"Could not scale ClickPipe, unexpected error: "+err.Error(),
			)
			return
		}
	}

	var pipeChanged bool
	var clickPipeUpdate api.ClickPipeUpdate

	if !plan.Name.Equal(state.Name) {
		pipeChanged = true
		clickPipeUpdate.Name = plan.Name.ValueStringPointer()
	}

	if !plan.Description.Equal(state.Description) {
		pipeChanged = true
		clickPipeUpdate.Description = plan.Description.ValueStringPointer()
	}

	if !plan.Source.Equal(state.Source) {
		source := c.extractSourceFromPlan(ctx, response.Diagnostics, plan, true)

		if source.Kafka != nil {
			pipeChanged = true
			clickPipeUpdate.Source = source
		} else {
			response.Diagnostics.AddError(
				"ClickPipe only supports Kafka source updates",
				"Only Kafka source updates are supported",
			)
		}
	}

	if !plan.Destination.Attributes()["columns"].Equal(state.Destination.Attributes()["columns"]) {
		pipeChanged = true
		destinationModel := models.ClickPipeDestinationModel{}
		response.Diagnostics.Append(plan.Destination.As(ctx, &destinationModel, basetypes.ObjectAsOptions{})...)
		destinationColumnsModels := make([]models.ClickPipeDestinationColumnModel, len(destinationModel.Columns.Elements()))
		response.Diagnostics.Append(destinationModel.Columns.ElementsAs(ctx, &destinationColumnsModels, false)...)

		clickPipeUpdate.Destination = &api.ClickPipeDestinationUpdate{
			Columns: make([]api.ClickPipeDestinationColumn, len(destinationColumnsModels)),
		}

		for i, columnModel := range destinationColumnsModels {
			clickPipeUpdate.Destination.Columns[i] = api.ClickPipeDestinationColumn{
				Name: columnModel.Name.ValueString(),
				Type: columnModel.Type.ValueString(),
			}
		}
	}

	if !plan.FieldMappings.Equal(state.FieldMappings) {
		pipeChanged = true
		fieldMappingsModels := make([]models.ClickPipeFieldMappingModel, len(plan.FieldMappings.Elements()))
		response.Diagnostics.Append(plan.FieldMappings.ElementsAs(ctx, &fieldMappingsModels, false)...)

		clickPipeUpdate.FieldMappings = make([]api.ClickPipeFieldMapping, len(fieldMappingsModels))
		for i, fieldMappingModel := range fieldMappingsModels {
			clickPipeUpdate.FieldMappings[i] = api.ClickPipeFieldMapping{
				SourceField:      fieldMappingModel.SourceField.ValueString(),
				DestinationField: fieldMappingModel.DestinationField.ValueString(),
			}
		}
	}

	if pipeChanged {
		if _, err := c.client.UpdateClickPipe(ctx, state.ServiceID.ValueString(), state.ID.ValueString(), clickPipeUpdate); err != nil {
			response.Diagnostics.AddError(
				"Error Updating ClickPipe",
				"Could not update ClickPipe, unexpected error: "+err.Error(),
			)
			return
		}
	}

	if _, err := c.client.WaitForClickPipeState(ctx, state.ServiceID.ValueString(), state.ID.ValueString(), func(state string) bool {
		return state == plan.State.ValueString()
	}, clickPipeStateChangeMaxWaitSeconds); err != nil {
		response.Diagnostics.AddWarning(
			"ClickPipe didn't reach the desired state",
			err.Error(),
		)
	}

	if err := c.syncClickPipeState(ctx, &plan); err != nil {
		response.Diagnostics.AddError(
			"Error Reading ClickPipe",
			"Could not read ClickPipe, unexpected error: "+err.Error(),
		)
		return
	}

	diags = response.State.Set(ctx, plan)
	response.Diagnostics.Append(diags...)
}

func (c *ClickPipeResource) Delete(ctx context.Context, request resource.DeleteRequest, response *resource.DeleteResponse) {
	var state models.ClickPipeResourceModel
	diags := request.State.Get(ctx, &state)
	response.Diagnostics.Append(diags...)
	if response.Diagnostics.HasError() {
		return
	}

	if err := c.client.DeleteClickPipe(ctx, state.ServiceID.ValueString(), state.ID.ValueString()); err != nil {
		response.Diagnostics.AddError(
			"Error Deleting ClickPipe",
			"Could not delete ClickPipe, unexpected error: "+err.Error(),
		)
	}
}
